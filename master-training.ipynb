{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"master-training.ipynb","provenance":[{"file_id":"https://github.com/porouspaper/svo-experiments/blob/master/master-training.ipynb","timestamp":1594301592823}],"collapsed_sections":[],"mount_file_id":"153ZLVrR2mEG85YjweedRnbzLH5GGxawu","authorship_tag":"ABX9TyNwGlgd+9ergDA/BRm7kjh+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"o-gfQLw1AcrE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":975},"executionInfo":{"status":"ok","timestamp":1596747654814,"user_tz":300,"elapsed":20634,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"4bb08697-9494-4482-b2d4-3e8177857a55"},"source":["!pip install tf-agents\n","!pip install --user tensorflow==2.2.0\n","!pip install --user tensorflow-probability==0.10.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf-agents in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: gin-config==0.1.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.1.3)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.18.5)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.15.0)\n","Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (3.12.4)\n","Requirement already satisfied: tensorflow-probability>=0.9.0 in /root/.local/lib/python3.6/site-packages (from tf-agents) (0.10.0)\n","Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.3->tf-agents) (49.2.0)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf-agents) (0.3.3)\n","Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf-agents) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf-agents) (4.4.2)\n","Requirement already satisfied: tensorflow==2.2.0 in /root/.local/lib/python3.6/site-packages (2.2.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.34.2)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.9.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n","Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /root/.local/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.2.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.30.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /root/.local/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.2.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (49.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n","Requirement already satisfied: tensorflow-probability==0.10.0 in /root/.local/lib/python3.6/site-packages (0.10.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.0) (4.4.2)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.0) (0.3.3)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.0) (1.18.5)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.0) (1.15.0)\n","Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.0) (1.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LpKpVqoKCh6F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596722146246,"user_tz":300,"elapsed":122373,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"38085fbb-4e38-4c1c-8c2f-66c1c38ec9db"},"source":["!pip list -v"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Package                  Version         Location                                 Installer\n","------------------------ --------------- ---------------------------------------- ---------\n","absl-py                  0.9.0           /usr/local/lib/python3.6/dist-packages   pip      \n","alabaster                0.7.12          /usr/local/lib/python3.6/dist-packages   pip      \n","albumentations           0.1.12          /usr/local/lib/python3.6/dist-packages   pip      \n","altair                   4.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","argon2-cffi              20.1.0          /usr/local/lib/python3.6/dist-packages   pip      \n","asgiref                  3.2.10          /usr/local/lib/python3.6/dist-packages   pip      \n","astor                    0.8.1           /usr/local/lib/python3.6/dist-packages   pip      \n","astropy                  4.0.1.post1     /usr/local/lib/python3.6/dist-packages   pip      \n","astunparse               1.6.3           /usr/local/lib/python3.6/dist-packages   pip      \n","atari-py                 0.2.6           /usr/local/lib/python3.6/dist-packages   pip      \n","atomicwrites             1.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","attrs                    19.3.0          /usr/local/lib/python3.6/dist-packages   pip      \n","audioread                2.1.8           /usr/local/lib/python3.6/dist-packages   pip      \n","autograd                 1.3             /usr/local/lib/python3.6/dist-packages   pip      \n","Babel                    2.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","backcall                 0.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","beautifulsoup4           4.6.3           /usr/local/lib/python3.6/dist-packages   pip      \n","bleach                   3.1.5           /usr/local/lib/python3.6/dist-packages   pip      \n","blis                     0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","bokeh                    2.1.1           /usr/local/lib/python3.6/dist-packages   pip      \n","boto                     2.49.0          /usr/local/lib/python3.6/dist-packages   pip      \n","boto3                    1.14.33         /usr/local/lib/python3.6/dist-packages   pip      \n","botocore                 1.17.33         /usr/local/lib/python3.6/dist-packages   pip      \n","Bottleneck               1.3.2           /usr/local/lib/python3.6/dist-packages   pip      \n","branca                   0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","bs4                      0.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","CacheControl             0.12.6          /usr/local/lib/python3.6/dist-packages   pip      \n","cachetools               4.1.1           /usr/local/lib/python3.6/dist-packages   pip      \n","catalogue                1.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","certifi                  2020.6.20       /usr/local/lib/python3.6/dist-packages   pip      \n","cffi                     1.14.1          /usr/local/lib/python3.6/dist-packages   pip      \n","chainer                  7.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","chardet                  3.0.4           /usr/local/lib/python3.6/dist-packages   pip      \n","click                    7.1.2           /usr/local/lib/python3.6/dist-packages   pip      \n","cloudpickle              1.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","cmake                    3.12.0          /usr/local/lib/python3.6/dist-packages   pip      \n","cmdstanpy                0.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","colorlover               0.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","community                1.0.0b1         /usr/local/lib/python3.6/dist-packages   pip      \n","contextlib2              0.5.5           /usr/local/lib/python3.6/dist-packages   pip      \n","convertdate              2.2.1           /usr/local/lib/python3.6/dist-packages   pip      \n","coverage                 3.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","coveralls                0.5             /usr/local/lib/python3.6/dist-packages   pip      \n","crcmod                   1.7             /usr/local/lib/python3.6/dist-packages   pip      \n","cufflinks                0.17.3          /usr/local/lib/python3.6/dist-packages   pip      \n","cupy-cuda101             7.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","cvxopt                   1.2.5           /usr/local/lib/python3.6/dist-packages   pip      \n","cvxpy                    1.0.31          /usr/local/lib/python3.6/dist-packages   pip      \n","cycler                   0.10.0          /usr/local/lib/python3.6/dist-packages   pip      \n","cymem                    2.0.3           /usr/local/lib/python3.6/dist-packages   pip      \n","Cython                   0.29.21         /usr/local/lib/python3.6/dist-packages   pip      \n","daft                     0.0.4           /usr/local/lib/python3.6/dist-packages   pip      \n","dask                     2.12.0          /usr/local/lib/python3.6/dist-packages   pip      \n","dataclasses              0.7             /usr/local/lib/python3.6/dist-packages   pip      \n","datascience              0.10.6          /usr/local/lib/python3.6/dist-packages   pip      \n","decorator                4.4.2           /usr/local/lib/python3.6/dist-packages   pip      \n","defusedxml               0.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","descartes                1.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","dill                     0.3.2           /usr/local/lib/python3.6/dist-packages   pip      \n","distributed              1.25.3          /usr/local/lib/python3.6/dist-packages   pip      \n","Django                   3.0.8           /usr/local/lib/python3.6/dist-packages   pip      \n","dlib                     19.18.0         /usr/local/lib/python3.6/dist-packages   pip      \n","dm-tree                  0.1.5           /usr/local/lib/python3.6/dist-packages   pip      \n","docopt                   0.6.2           /usr/local/lib/python3.6/dist-packages   pip      \n","docutils                 0.15.2          /usr/local/lib/python3.6/dist-packages   pip      \n","dopamine-rl              1.0.5           /usr/local/lib/python3.6/dist-packages   pip      \n","earthengine-api          0.1.229         /usr/local/lib/python3.6/dist-packages   pip      \n","easydict                 1.9             /usr/local/lib/python3.6/dist-packages   pip      \n","ecos                     2.0.7.post1     /usr/local/lib/python3.6/dist-packages   pip      \n","editdistance             0.5.3           /usr/local/lib/python3.6/dist-packages   pip      \n","en-core-web-sm           2.2.5           /usr/local/lib/python3.6/dist-packages   pip      \n","entrypoints              0.3             /usr/local/lib/python3.6/dist-packages   pip      \n","ephem                    3.7.7.1         /usr/local/lib/python3.6/dist-packages   pip      \n","et-xmlfile               1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","fa2                      0.3.5           /usr/local/lib/python3.6/dist-packages   pip      \n","fancyimpute              0.4.3           /usr/local/lib/python3.6/dist-packages   pip      \n","fastai                   1.0.61          /usr/local/lib/python3.6/dist-packages   pip      \n","fastdtw                  0.3.4           /usr/local/lib/python3.6/dist-packages   pip      \n","fastprogress             0.2.4           /usr/local/lib/python3.6/dist-packages   pip      \n","fastrlock                0.5             /usr/local/lib/python3.6/dist-packages   pip      \n","fbprophet                0.6             /usr/local/lib/python3.6/dist-packages            \n","feather-format           0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","featuretools             0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","filelock                 3.0.12          /usr/local/lib/python3.6/dist-packages   pip      \n","firebase-admin           4.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","fix-yahoo-finance        0.0.22          /usr/local/lib/python3.6/dist-packages   pip      \n","Flask                    1.1.2           /usr/local/lib/python3.6/dist-packages   pip      \n","folium                   0.8.3           /usr/local/lib/python3.6/dist-packages   pip      \n","fsspec                   0.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","future                   0.16.0          /usr/local/lib/python3.6/dist-packages   pip      \n","gast                     0.3.3           /usr/local/lib/python3.6/dist-packages   pip      \n","GDAL                     2.2.2           /usr/lib/python3/dist-packages                    \n","gdown                    3.6.4           /usr/local/lib/python3.6/dist-packages   pip      \n","gensim                   3.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","geographiclib            1.50            /usr/local/lib/python3.6/dist-packages   pip      \n","geopy                    1.17.0          /usr/local/lib/python3.6/dist-packages   pip      \n","gin-config               0.1.3           /usr/local/lib/python3.6/dist-packages   pip      \n","glob2                    0.7             /usr/local/lib/python3.6/dist-packages   pip      \n","google                   2.0.3           /usr/local/lib/python3.6/dist-packages   pip      \n","google-api-core          1.16.0          /usr/local/lib/python3.6/dist-packages   pip      \n","google-api-python-client 1.7.12          /usr/local/lib/python3.6/dist-packages   pip      \n","google-auth              1.17.2          /usr/local/lib/python3.6/dist-packages   pip      \n","google-auth-httplib2     0.0.4           /usr/local/lib/python3.6/dist-packages   pip      \n","google-auth-oauthlib     0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-bigquery    1.21.0          /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-core        1.0.3           /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-datastore   1.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-firestore   1.7.0           /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-language    1.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-storage     1.18.1          /usr/local/lib/python3.6/dist-packages   pip      \n","google-cloud-translate   1.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","google-colab             1.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","google-pasta             0.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","google-resumable-media   0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","googleapis-common-protos 1.52.0          /usr/local/lib/python3.6/dist-packages   pip      \n","googledrivedownloader    0.4             /usr/local/lib/python3.6/dist-packages   pip      \n","graphviz                 0.10.1          /usr/local/lib/python3.6/dist-packages   pip      \n","grpcio                   1.30.0          /usr/local/lib/python3.6/dist-packages   pip      \n","gspread                  3.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","gspread-dataframe        3.0.7           /usr/local/lib/python3.6/dist-packages   pip      \n","gym                      0.17.2          /usr/local/lib/python3.6/dist-packages   pip      \n","h5py                     2.10.0          /usr/local/lib/python3.6/dist-packages   pip      \n","HeapDict                 1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","holidays                 0.9.12          /usr/local/lib/python3.6/dist-packages   pip      \n","holoviews                1.13.3          /usr/local/lib/python3.6/dist-packages   pip      \n","html5lib                 1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","httpimport               0.5.18          /usr/local/lib/python3.6/dist-packages   pip      \n","httplib2                 0.17.4          /usr/local/lib/python3.6/dist-packages   pip      \n","httplib2shim             0.0.3           /usr/local/lib/python3.6/dist-packages   pip      \n","humanize                 0.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","hyperopt                 0.1.2           /usr/local/lib/python3.6/dist-packages   pip      \n","ideep4py                 2.0.0.post3     /usr/local/lib/python3.6/dist-packages   pip      \n","idna                     2.10            /usr/local/lib/python3.6/dist-packages   pip      \n","image                    1.5.32          /usr/local/lib/python3.6/dist-packages   pip      \n","imageio                  2.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","imagesize                1.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","imbalanced-learn         0.4.3           /usr/local/lib/python3.6/dist-packages   pip      \n","imblearn                 0.0             /usr/local/lib/python3.6/dist-packages   pip      \n","imgaug                   0.2.9           /usr/local/lib/python3.6/dist-packages   pip      \n","importlib-metadata       1.7.0           /usr/local/lib/python3.6/dist-packages   pip      \n","imutils                  0.5.3           /usr/local/lib/python3.6/dist-packages   pip      \n","inflect                  2.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","iniconfig                1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","intel-openmp             2020.0.133      /usr/local/lib/python3.6/dist-packages   pip      \n","intervaltree             2.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","ipykernel                4.10.1          /usr/local/lib/python3.6/dist-packages   pip      \n","ipython                  5.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","ipython-genutils         0.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","ipython-sql              0.3.9           /usr/local/lib/python3.6/dist-packages   pip      \n","ipywidgets               7.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","itsdangerous             1.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","jax                      0.1.73          /usr/local/lib/python3.6/dist-packages   pip      \n","jaxlib                   0.1.52          /usr/local/lib/python3.6/dist-packages   pip      \n","jdcal                    1.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","jedi                     0.17.2          /usr/local/lib/python3.6/dist-packages   pip      \n","jieba                    0.42.1          /usr/local/lib/python3.6/dist-packages   pip      \n","Jinja2                   2.11.2          /usr/local/lib/python3.6/dist-packages   pip      \n","jmespath                 0.10.0          /usr/local/lib/python3.6/dist-packages   pip      \n","joblib                   0.16.0          /usr/local/lib/python3.6/dist-packages   pip      \n","jpeg4py                  0.1.4           /usr/local/lib/python3.6/dist-packages   pip      \n","jsonschema               2.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","jupyter                  1.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","jupyter-client           5.3.5           /usr/local/lib/python3.6/dist-packages   pip      \n","jupyter-console          5.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","jupyter-core             4.6.3           /usr/local/lib/python3.6/dist-packages   pip      \n","kaggle                   1.5.6           /usr/local/lib/python3.6/dist-packages   pip      \n","kapre                    0.1.3.1         /usr/local/lib/python3.6/dist-packages   pip      \n","Keras                    2.4.3           /usr/local/lib/python3.6/dist-packages   pip      \n","Keras-Preprocessing      1.1.2           /usr/local/lib/python3.6/dist-packages   pip      \n","keras-vis                0.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","kiwisolver               1.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","knnimpute                0.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","librosa                  0.6.3           /usr/local/lib/python3.6/dist-packages   pip      \n","lightgbm                 2.2.3           /usr/local/lib/python3.6/dist-packages   pip      \n","llvmlite                 0.31.0          /usr/local/lib/python3.6/dist-packages   pip      \n","lmdb                     0.98            /usr/local/lib/python3.6/dist-packages   pip      \n","lucid                    0.3.8           /usr/local/lib/python3.6/dist-packages   pip      \n","LunarCalendar            0.0.9           /usr/local/lib/python3.6/dist-packages   pip      \n","lxml                     4.2.6           /usr/local/lib/python3.6/dist-packages   pip      \n","Markdown                 3.2.2           /usr/local/lib/python3.6/dist-packages   pip      \n","MarkupSafe               1.1.1           /usr/local/lib/python3.6/dist-packages   pip      \n","matplotlib               3.2.2           /usr/local/lib/python3.6/dist-packages   pip      \n","matplotlib-venn          0.11.5          /usr/local/lib/python3.6/dist-packages   pip      \n","missingno                0.4.2           /usr/local/lib/python3.6/dist-packages   pip      \n","mistune                  0.8.4           /usr/local/lib/python3.6/dist-packages   pip      \n","mizani                   0.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","mkl                      2019.0          /usr/local/lib/python3.6/dist-packages   pip      \n","mlxtend                  0.14.0          /usr/local/lib/python3.6/dist-packages   pip      \n","more-itertools           8.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","moviepy                  0.2.3.5         /usr/local/lib/python3.6/dist-packages   pip      \n","mpmath                   1.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","msgpack                  1.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","multiprocess             0.70.10         /usr/local/lib/python3.6/dist-packages   pip      \n","multitasking             0.0.9           /usr/local/lib/python3.6/dist-packages   pip      \n","murmurhash               1.0.2           /usr/local/lib/python3.6/dist-packages   pip      \n","music21                  5.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","natsort                  5.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","nbconvert                5.6.1           /usr/local/lib/python3.6/dist-packages   pip      \n","nbformat                 5.0.7           /usr/local/lib/python3.6/dist-packages   pip      \n","networkx                 2.4             /usr/local/lib/python3.6/dist-packages   pip      \n","nibabel                  3.0.2           /usr/local/lib/python3.6/dist-packages   pip      \n","nltk                     3.2.5           /usr/local/lib/python3.6/dist-packages   pip      \n","notebook                 5.3.1           /usr/local/lib/python3.6/dist-packages   pip      \n","np-utils                 0.5.12.1        /usr/local/lib/python3.6/dist-packages   pip      \n","numba                    0.48.0          /usr/local/lib/python3.6/dist-packages   pip      \n","numexpr                  2.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","numpy                    1.18.5          /usr/local/lib/python3.6/dist-packages   pip      \n","nvidia-ml-py3            7.352.0         /usr/local/lib/python3.6/dist-packages   pip      \n","oauth2client             4.1.3           /usr/local/lib/python3.6/dist-packages   pip      \n","oauthlib                 3.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","okgrade                  0.4.3           /usr/local/lib/python3.6/dist-packages   pip      \n","opencv-contrib-python    4.1.2.30        /usr/local/lib/python3.6/dist-packages   pip      \n","opencv-python            4.1.2.30        /usr/local/lib/python3.6/dist-packages   pip      \n","openpyxl                 2.5.9           /usr/local/lib/python3.6/dist-packages   pip      \n","opt-einsum               3.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","osqp                     0.6.1           /usr/local/lib/python3.6/dist-packages   pip      \n","packaging                20.4            /usr/local/lib/python3.6/dist-packages   pip      \n","palettable               3.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pandas                   1.0.5           /usr/local/lib/python3.6/dist-packages   pip      \n","pandas-datareader        0.8.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pandas-gbq               0.11.0          /usr/local/lib/python3.6/dist-packages   pip      \n","pandas-profiling         1.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pandocfilters            1.4.2           /usr/local/lib/python3.6/dist-packages   pip      \n","panel                    0.9.7           /usr/local/lib/python3.6/dist-packages   pip      \n","param                    1.9.3           /usr/local/lib/python3.6/dist-packages   pip      \n","parso                    0.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pathlib                  1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","patsy                    0.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pexpect                  4.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pickleshare              0.7.5           /usr/local/lib/python3.6/dist-packages   pip      \n","Pillow                   7.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pip                      19.3.1          /usr/local/lib/python3.6/dist-packages   pip      \n","pip-tools                4.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","plac                     1.1.3           /usr/local/lib/python3.6/dist-packages   pip      \n","plotly                   4.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","plotnine                 0.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pluggy                   0.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","portpicker               1.3.1           /usr/local/lib/python3.6/dist-packages   pip      \n","prefetch-generator       1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","preshed                  3.0.2           /usr/local/lib/python3.6/dist-packages   pip      \n","prettytable              0.7.2           /usr/local/lib/python3.6/dist-packages   pip      \n","progressbar2             3.38.0          /usr/local/lib/python3.6/dist-packages   pip      \n","prometheus-client        0.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","promise                  2.3             /usr/local/lib/python3.6/dist-packages   pip      \n","prompt-toolkit           1.0.18          /usr/local/lib/python3.6/dist-packages   pip      \n","protobuf                 3.12.4          /usr/local/lib/python3.6/dist-packages   pip      \n","psutil                   5.4.8           /usr/local/lib/python3.6/dist-packages   pip      \n","psycopg2                 2.7.6.1         /usr/local/lib/python3.6/dist-packages   pip      \n","ptyprocess               0.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","py                       1.9.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pyarrow                  0.14.1          /usr/local/lib/python3.6/dist-packages   pip      \n","pyasn1                   0.4.8           /usr/local/lib/python3.6/dist-packages   pip      \n","pyasn1-modules           0.2.8           /usr/local/lib/python3.6/dist-packages   pip      \n","pycocotools              2.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pycparser                2.20            /usr/local/lib/python3.6/dist-packages   pip      \n","pyct                     0.4.6           /usr/local/lib/python3.6/dist-packages   pip      \n","pydata-google-auth       1.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pydot                    1.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pydot-ng                 2.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pydotplus                2.0.2           /usr/local/lib/python3.6/dist-packages   pip      \n","PyDrive                  1.3.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pyemd                    0.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pyglet                   1.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","Pygments                 2.1.3           /usr/local/lib/python3.6/dist-packages   pip      \n","pygobject                3.26.1          /usr/lib/python3/dist-packages                    \n","pymc3                    3.7             /usr/local/lib/python3.6/dist-packages   pip      \n","PyMeeus                  0.3.7           /usr/local/lib/python3.6/dist-packages   pip      \n","pymongo                  3.11.0          /usr/local/lib/python3.6/dist-packages   pip      \n","pymystem3                0.2.0           /usr/local/lib/python3.6/dist-packages   pip      \n","PyOpenGL                 3.1.5           /usr/local/lib/python3.6/dist-packages   pip      \n","pyparsing                2.4.7           /usr/local/lib/python3.6/dist-packages   pip      \n","pyrsistent               0.16.0          /usr/local/lib/python3.6/dist-packages   pip      \n","pysndfile                1.3.8           /usr/local/lib/python3.6/dist-packages   pip      \n","PySocks                  1.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","pystan                   2.19.1.1        /usr/local/lib/python3.6/dist-packages   pip      \n","pytest                   3.6.4           /usr/local/lib/python3.6/dist-packages   pip      \n","python-apt               1.6.5+ubuntu0.3 /usr/lib/python3/dist-packages                    \n","python-chess             0.23.11         /usr/local/lib/python3.6/dist-packages   pip      \n","python-dateutil          2.8.1           /usr/local/lib/python3.6/dist-packages   pip      \n","python-louvain           0.14            /usr/local/lib/python3.6/dist-packages   pip      \n","python-slugify           4.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","python-utils             2.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","pytz                     2018.9          /usr/local/lib/python3.6/dist-packages   pip      \n","pyviz-comms              0.7.6           /usr/local/lib/python3.6/dist-packages   pip      \n","PyWavelets               1.1.1           /usr/local/lib/python3.6/dist-packages   pip      \n","PyYAML                   3.13            /usr/local/lib/python3.6/dist-packages   pip      \n","pyzmq                    19.0.2          /usr/local/lib/python3.6/dist-packages   pip      \n","qtconsole                4.7.5           /usr/local/lib/python3.6/dist-packages   pip      \n","QtPy                     1.9.0           /usr/local/lib/python3.6/dist-packages   pip      \n","regex                    2019.12.20      /usr/local/lib/python3.6/dist-packages   pip      \n","requests                 2.23.0          /usr/local/lib/python3.6/dist-packages   pip      \n","requests-oauthlib        1.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","resampy                  0.2.2           /usr/local/lib/python3.6/dist-packages   pip      \n","retrying                 1.3.3           /usr/local/lib/python3.6/dist-packages   pip      \n","rpy2                     3.2.7           /usr/local/lib/python3.6/dist-packages   pip      \n","rsa                      4.6             /usr/local/lib/python3.6/dist-packages   pip      \n","s3fs                     0.4.2           /usr/local/lib/python3.6/dist-packages   pip      \n","s3transfer               0.3.3           /usr/local/lib/python3.6/dist-packages   pip      \n","scikit-image             0.16.2          /usr/local/lib/python3.6/dist-packages   pip      \n","scikit-learn             0.22.2.post1    /usr/local/lib/python3.6/dist-packages   pip      \n","scipy                    1.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","screen-resolution-extra  0.0.0           /usr/lib/python3/dist-packages                    \n","scs                      2.1.2           /usr/local/lib/python3.6/dist-packages   pip      \n","seaborn                  0.10.1          /usr/local/lib/python3.6/dist-packages   pip      \n","Send2Trash               1.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","setuptools               49.2.0          /usr/local/lib/python3.6/dist-packages   pip      \n","setuptools-git           1.2             /usr/local/lib/python3.6/dist-packages   pip      \n","Shapely                  1.7.0           /usr/local/lib/python3.6/dist-packages   pip      \n","simplegeneric            0.8.1           /usr/local/lib/python3.6/dist-packages   pip      \n","six                      1.15.0          /usr/local/lib/python3.6/dist-packages   pip      \n","sklearn                  0.0             /usr/local/lib/python3.6/dist-packages   pip      \n","sklearn-pandas           1.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","smart-open               2.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","snowballstemmer          2.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","sortedcontainers         2.2.2           /usr/local/lib/python3.6/dist-packages   pip      \n","spacy                    2.2.4           /usr/local/lib/python3.6/dist-packages   pip      \n","Sphinx                   1.8.5           /usr/local/lib/python3.6/dist-packages   pip      \n","sphinxcontrib-websupport 1.2.3           /usr/local/lib/python3.6/dist-packages   pip      \n","SQLAlchemy               1.3.18          /usr/local/lib/python3.6/dist-packages   pip      \n","sqlparse                 0.3.1           /usr/local/lib/python3.6/dist-packages   pip      \n","srsly                    1.0.2           /usr/local/lib/python3.6/dist-packages   pip      \n","statsmodels              0.10.2          /usr/local/lib/python3.6/dist-packages   pip      \n","sympy                    1.1.1           /usr/local/lib/python3.6/dist-packages   pip      \n","tables                   3.4.4           /usr/local/lib/python3.6/dist-packages   pip      \n","tabulate                 0.8.7           /usr/local/lib/python3.6/dist-packages   pip      \n","tblib                    1.7.0           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorboard              2.2.2           /root/.local/lib/python3.6/site-packages pip      \n","tensorboard-plugin-wit   1.7.0           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorboardcolab         0.0.22          /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow               2.2.0           /root/.local/lib/python3.6/site-packages pip      \n","tensorflow-addons        0.8.3           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow-datasets      2.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow-estimator     2.2.0           /root/.local/lib/python3.6/site-packages pip      \n","tensorflow-gcs-config    2.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow-hub           0.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow-metadata      0.22.2          /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow-privacy       0.2.2           /usr/local/lib/python3.6/dist-packages   pip      \n","tensorflow-probability   0.10.0          /root/.local/lib/python3.6/site-packages pip      \n","termcolor                1.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","terminado                0.8.3           /usr/local/lib/python3.6/dist-packages   pip      \n","testpath                 0.4.4           /usr/local/lib/python3.6/dist-packages   pip      \n","text-unidecode           1.3             /usr/local/lib/python3.6/dist-packages   pip      \n","textblob                 0.15.3          /usr/local/lib/python3.6/dist-packages   pip      \n","textgenrnn               1.4.1           /usr/local/lib/python3.6/dist-packages   pip      \n","tf-agents                0.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","Theano                   1.0.5           /usr/local/lib/python3.6/dist-packages   pip      \n","thinc                    7.4.0           /usr/local/lib/python3.6/dist-packages   pip      \n","tifffile                 2020.7.24       /usr/local/lib/python3.6/dist-packages   pip      \n","toml                     0.10.1          /usr/local/lib/python3.6/dist-packages   pip      \n","toolz                    0.10.0          /usr/local/lib/python3.6/dist-packages   pip      \n","torch                    1.6.0+cu101     /usr/local/lib/python3.6/dist-packages   pip      \n","torchsummary             1.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","torchtext                0.3.1           /usr/local/lib/python3.6/dist-packages   pip      \n","torchvision              0.7.0+cu101     /usr/local/lib/python3.6/dist-packages   pip      \n","tornado                  5.1.1           /usr/local/lib/python3.6/dist-packages   pip      \n","tqdm                     4.41.1          /usr/local/lib/python3.6/dist-packages   pip      \n","traitlets                4.3.3           /usr/local/lib/python3.6/dist-packages   pip      \n","tweepy                   3.6.0           /usr/local/lib/python3.6/dist-packages   pip      \n","typeguard                2.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","typing-extensions        3.7.4.2         /usr/local/lib/python3.6/dist-packages   pip      \n","tzlocal                  1.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","umap-learn               0.4.6           /usr/local/lib/python3.6/dist-packages   pip      \n","uritemplate              3.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","urllib3                  1.24.3          /usr/local/lib/python3.6/dist-packages   pip      \n","vega-datasets            0.8.0           /usr/local/lib/python3.6/dist-packages   pip      \n","wasabi                   0.7.1           /usr/local/lib/python3.6/dist-packages   pip      \n","wcwidth                  0.2.5           /usr/local/lib/python3.6/dist-packages   pip      \n","webencodings             0.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","Werkzeug                 1.0.1           /usr/local/lib/python3.6/dist-packages   pip      \n","wheel                    0.34.2          /usr/local/lib/python3.6/dist-packages   pip      \n","widgetsnbextension       3.5.1           /usr/local/lib/python3.6/dist-packages   pip      \n","wordcloud                1.5.0           /usr/local/lib/python3.6/dist-packages   pip      \n","wrapt                    1.12.1          /usr/local/lib/python3.6/dist-packages   pip      \n","xarray                   0.15.1          /usr/local/lib/python3.6/dist-packages   pip      \n","xgboost                  0.90            /usr/local/lib/python3.6/dist-packages   pip      \n","xkit                     0.0.0           /usr/lib/python3/dist-packages                    \n","xlrd                     1.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n","xlwt                     1.3.0           /usr/local/lib/python3.6/dist-packages   pip      \n","yellowbrick              0.9.1           /usr/local/lib/python3.6/dist-packages   pip      \n","zict                     2.0.0           /usr/local/lib/python3.6/dist-packages   pip      \n","zipp                     3.1.0           /usr/local/lib/python3.6/dist-packages   pip      \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2R6erdyYivh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1596722165055,"user_tz":300,"elapsed":141169,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"c12e1157-c8fa-4845-c855-58831fdb9727"},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=b39e8fed91e0f39aaffc1b55dfcfc76ac22e7d9480255fd703cd607c54eb28b6\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.2 GB  | Proc size: 1.0 GB\n","GPU RAM Free: 14852MB | Used: 227MB | Util   2% | Total 15079MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oCi38DvSIB7f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"ok","timestamp":1596747685175,"user_tz":300,"elapsed":50971,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"a28aecc6-fa17-4745-919a-8f4fd3d7cd63"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import abc\n","import tensorflow as tf\n","import numpy as np\n","import random\n","\n","import base64\n","import IPython\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import tempfile\n","import zipfile\n","import tensorflow_probability as tfp\n","\n","from tf_agents.environments import py_environment\n","from tf_agents.environments import tf_environment\n","from tf_agents.environments import tf_py_environment\n","from tf_agents.environments import utils\n","from tf_agents.specs import array_spec\n","from tf_agents.environments import wrappers\n","from tf_agents.trajectories import time_step as ts\n","from tf_agents.trajectories import policy_step as ps\n","from tf_agents.networks import actor_distribution_network\n","from tf_agents.networks import value_network\n","from tf_agents.networks import network\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\n","from tf_agents.trajectories import trajectory\n","from tf_agents.utils import common\n","from tf_agents.distributions.utils import SquashToSpecNormal\n","from tf_agents.networks import normal_projection_network\n","from tf_agents.policies import random_tf_policy\n","from tf_agents.policies import policy_saver\n","from tf_agents.specs import tensor_spec\n","from tf_agents.agents.sac import tanh_normal_projection_network\n","\n","from tf_agents.agents.ddpg import critic_network\n","from tf_agents.agents.sac import sac_agent\n","from tf_agents.agents.ppo import ppo_clip_agent\n","\n","\n","tf.compat.v1.enable_v2_behavior()\n","\n","import os\n","import shutil\n","\n","try:\n","  from google.colab import files\n","except ImportError:\n","  files = None\n","\n","\n","from google.colab import drive \n","drive.mount('/content/gdrive') \n","\n","tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n","\n","\n","%xmode Verbose"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n","Mounted at /content/gdrive\n","Exception reporting mode: Verbose\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LWrT_mfUZkm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747685177,"user_tz":300,"elapsed":7435,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["# use \"num_iterations = 1e6\" for better results,\n","# 1e5 is just so this doesn't take too long. \n","num_iterations =  1000# @param {type:\"integer\"}\n","\n","initial_collect_steps = 10000 # @param {type:\"integer\"} \n","collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n","replay_buffer_capacity = 1000000 # @param {type:\"integer\"}\n","\n","batch_size = 256 # @param {type:\"integer\"}\n","\n","critic_learning_rate = 3e-4 # @param {type:\"number\"}\n","actor_learning_rate = 3e-4 # @param {type:\"number\"}\n","alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n","target_update_tau = 0.005 # @param {type:\"number\"}\n","target_update_period = 1 # @param {type:\"number\"}\n","gamma = 0.99 # @param {type:\"number\"}\n","reward_scale_factor = 1.0 # @param {type:\"number\"}\n","gradient_clipping = None # @param\n","\n","actor_fc_layer_params = (100, 100, 100)\n","critic_joint_fc_layer_params = (100, 100, 100)\n","\n","log_interval =  1000# @param {type:\"integer\"}\n","\n","num_eval_episodes =  10# @param {type:\"integer\"}\n","eval_interval = 10 # @param {type:\"integer\"}\n","\n","eval_returns_amt = 100 # @param {type:\"integer\"}\n","\n","\n","\n","collect_episodes_per_iteration = 10 # @param {type:\"integer\"}\n","fc_layer_params = (256,256,256)\n","learning_rate = 1e-3 # @param {type:\"number\"}\n","log_interval = 10 # @param {type:\"integer\"}\n","num_epochs = 10"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qHOZ1AMSZ1y","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596747688372,"user_tz":300,"elapsed":10189,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"8654bac2-34f6-41d7-9c74-5d0eeb0fdbe7"},"source":["myrho = \"270\" # @param {type:\"string\"}\n","extension = \"ppo-pgg-1\" # @param {type:\"string\"}\n","_RHO = np.radians(int(myrho)) \n","fname = \"svo-\" + myrho + \"-\" + extension\n","\n","import sys\n","sys.path.append('/content/gdrive/My Drive/colab+git')\n","import pgg_add_ppo as pgg\n","\n","\n","\n","def angular_reward(rho):\n","  return (lambda x, y: np.cos(rho) * x + np.sin(rho) * y)\n","def reward_fun(self, other):\n","  f = angular_reward(_RHO)\n","  return f(self, other)\n","\n","pgg.reward_fun = reward_fun\n","\n","\n","def create_zip_file(dirname, base_filename):\n","  return shutil.make_archive(base_filename, 'zip', dirname)\n","\n","def upload_and_unzip_file_to(dirname):\n","  if files is None:\n","    return\n","  uploaded = files.upload()\n","  for fn in uploaded.keys():\n","    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","        name=fn, length=len(uploaded[fn])))\n","    shutil.rmtree(dirname)\n","    zip_files = zipfile.ZipFile(io.BytesIO(uploaded[fn]), 'r')\n","    zip_files.extractall(dirname)\n","    zip_files.close()\n","\n","reward_fun(70, 70)\n"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-70.00000000000001"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ZRJDMuHeIIyf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688376,"user_tz":300,"elapsed":9884,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["\n","def construct_agent(observation_spec, action_spec, time_step_spec):\n","  agent_array_action_spec = action_spec\n","  agent_array_observation_spec = observation_spec\n","\n","  agent_action_spec = tensor_spec.from_spec(agent_array_action_spec)\n","  agent_observation_spec = tensor_spec.from_spec(agent_array_observation_spec)\n","\n","\n","  critic_net = critic_network.CriticNetwork(\n","    (agent_observation_spec, agent_action_spec),\n","    observation_fc_layer_params=None,\n","    action_fc_layer_params=None,\n","    joint_fc_layer_params=critic_joint_fc_layer_params)\n","\n","\n","  actor_net = actor_distribution_network.ActorDistributionNetwork(\n","    agent_observation_spec,\n","    agent_action_spec,\n","    fc_layer_params=actor_fc_layer_params,\n","    continuous_projection_net=tanh_normal_projection_network\n","        .TanhNormalProjectionNetwork\n","    )\n","\n","  value_net = value_network.ValueNetwork(observation_spec)\n","\n","  global_step = tf.compat.v1.train.get_or_create_global_step()\n","\n","  tf_agent = sac_agent.SacAgent(\n","      time_step_spec,\n","      agent_action_spec,\n","      actor_network=actor_net,\n","      critic_network=critic_net,\n","      actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n","          learning_rate=actor_learning_rate),\n","      critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n","          learning_rate=critic_learning_rate),\n","      alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n","          learning_rate=alpha_learning_rate),\n","      target_update_tau=target_update_tau,\n","      target_update_period=target_update_period,\n","      td_errors_loss_fn=tf.compat.v1.losses.mean_squared_error,\n","      gamma=gamma,\n","      reward_scale_factor=reward_scale_factor,\n","      gradient_clipping=gradient_clipping,\n","      train_step_counter=global_step)\n","  tf_agent.initialize()\n","  return tf_agent\n","\n","def construct_ppo_agent(observation_spec, action_spec, time_step_spec):\n","  agent_array_action_spec = action_spec\n","  agent_array_observation_spec = observation_spec\n","\n","  agent_action_spec = tensor_spec.from_spec(agent_array_action_spec)\n","  agent_observation_spec = tensor_spec.from_spec(agent_array_observation_spec)\n","\n","  actor_net = actor_distribution_network.ActorDistributionNetwork(\n","    agent_observation_spec,\n","    agent_action_spec,\n","    fc_layer_params=fc_layer_params)\n","\n","\n","  optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n","  value_net = value_network.ValueNetwork(agent_observation_spec)\n","\n","  global_step = tf.compat.v1.train.get_or_create_global_step()\n","\n","  tf_agent = ppo_clip_agent.PPOClipAgent(\n","          time_step_spec,\n","          agent_action_spec,\n","          optimizer,\n","          actor_net=actor_net,\n","          value_net=value_net,\n","          entropy_regularization=0.0,\n","          importance_ratio_clipping=0.2,\n","          normalize_observations=True,\n","          normalize_rewards=True,\n","          use_gae=True,\n","          num_epochs=num_epochs,\n","          debug_summaries=False,\n","          summarize_grads_and_vars=True,\n","          train_step_counter=global_step)\n","\n","  tf_agent.initialize()\n","\n","  return tf_agent\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8pr8Qn7IOZt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688380,"user_tz":300,"elapsed":9558,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["\n","\n","def create_env():\n","  return tf_py_environment.TFPyEnvironment(pgg.PublicGoodsEnv())\n","\n","def validate_random(environment, episodes):\n","  time_step_spec = environment.time_step_spec()\n","  action_spec = environment.action_spec()\n","\n","  episode_count = 0\n","  time_step = environment.reset()\n","\n","  while episode_count < episodes:\n","    if not array_spec.check_arrays_nest(time_step, time_step_spec):\n","      raise ValueError(\n","          'Given `time_step`: %r does not match expected `time_step_spec`: %r' %\n","          (time_step, time_step_spec))\n","    obs = time_step.observation\n","    action0 = [random.uniform(0, 1)]\n","    action1 = [random.uniform(0, 1)]\n","\n","    new_action = [action0[0], action1[0]]\n","    time_step = environment.step(new_action)\n","    print(time_step)\n","\n","    if time_step.is_last():\n","        episode_count += 1\n","        time_step = environment.reset()\n","\n","#validate_random(pgg.PublicGoodsEnv(), 5)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOZwRy8MR6z6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688381,"user_tz":300,"elapsed":9199,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def make_checkpoint(tf_agent, train_env, checkpoint_dir, replay_buffer):\n","  train_checkpointer = common.Checkpointer(\n","      ckpt_dir=checkpoint_dir,\n","      max_to_keep=1,\n","      agent=tf_agent,\n","      policy=tf_agent.policy,\n","      replay_buffer=replay_buffer,\n","      global_step=tf_agent.train_step_counter\n","  )\n","\n","  return train_checkpointer\n","\n","#need to replace train_checkpointer"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"1uaZRfFYIVsx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688383,"user_tz":300,"elapsed":8851,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def self_play_train(tf_agent, train_env, eval_env, train_checkpointer, replay_buffer):\n","  \"\"\"GPUs = GPU.getGPUs()\n","  gpu = GPUs[0]\n","  def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","  printm()\"\"\"\n","  def construct_intended_action(policy0, policy1, time_step):\n","    return pgg.construct_intended_action(policy0, policy1, time_step)\n","  \n","  def compute_avg_return(environment, policy0, policy1, num_episodes=10):\n","\n","    total_return = 0.0\n","    for _ in range(num_episodes):\n","\n","      time_step = environment.reset()\n","      episode_return = 0.0\n","\n","      while not time_step.is_last():\n","        new_action = construct_intended_action(policy0, policy1, time_step, False)\n","        action_step = ps.PolicyStep(action=new_action)\n","\n","        time_step = environment.step(action_step.action)\n","        \n","        episode_return += time_step.reward\n","      total_return += episode_return\n","\n","    avg_return = total_return / num_episodes\n","    return avg_return.numpy()[0]\n","\n","\n","  \"\"\"rb_checkpointer = common.Checkpointer(\n","        ckpt_dir=os.path.join(tempdir, 'replay_buffer'),\n","        max_to_keep=1,\n","        replay_buffer=replay_buffer)\"\"\"\n","  \n","  \"\"\"upload_and_unzip_file_to(os.path.join(tempdir, 'replay_buffer'))\n","  rb_checkpointer.initialize_or_restore()\"\"\"\n","  \n","  def collect_step(environment, policy0, policy1):\n","\n","    time_step = environment.current_time_step()\n","\n","    new_action = construct_intended_action(policy0, policy1, time_step, False)\n","\n","    action_step = ps.PolicyStep(action=new_action)\n","\n","\n","    next_time_step = environment.step(action_step.action)\n","\n","    traj = trajectory.from_transition(time_step, action_step, next_time_step) #expand \n","\n","    # Add trajectory to the replay buffer\n","    replay_buffer.add_batch(traj)\n","\n","  def collect_data(env, policy0, policy1, steps):\n","    for _ in range(steps):\n","      collect_step(env, policy0, policy1)\n","\n","  collect_data(train_env, tf_agent.collect_policy, tf_agent.collect_policy, steps=100)\n","\n","  # Dataset generates trajectories with shape [Bx2x...]\n","  dataset = replay_buffer.as_dataset(\n","    num_parallel_calls=3, \n","    sample_batch_size=batch_size, \n","    num_steps=2).prefetch(3)\n","\n","  iterator = iter(dataset)\n","\n","  \n","  with tf.device('/device:GPU:0'):\n","    try:\n","      %%time\n","    except:\n","      pass\n","\n","\n","\n","    # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n","    tf_agent.train = common.function(tf_agent.train)\n","\n","    # Reset the train step\n","    tf_agent.train_step_counter.assign(0)\n","\n","    # Evaluate the agent's policy once before training.\n","    avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","    returns = [avg_return]\n","\n","    for _ in range(num_iterations):\n","      \"\"\"printm()\n","      print(\"CPU usage: {}\".format(psutil.cpu_percent()))\n","      GPU.showUtilization()\"\"\"\n","      # Collect a few steps using collect_policy and save to the replay buffer.\n","      for _ in range(collect_steps_per_iteration):\n","        collect_step(train_env, tf_agent.collect_policy, tf_agent.collect_policy)\n","\n","      # Sample a batch of data from the buffer and update the agent's network.\n","\n","      experience, unused_info = next(iterator)\n","      train_loss = tf_agent.train(experience)\n","\n","      step = tf_agent.train_step_counter.numpy()\n","\n","      if step % log_interval == 0:\n","        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n","\n","      if step % eval_interval == 0:\n","        avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n","        returns.append(avg_return)\n","\n","\n","    steps = range(0, num_iterations + 1, eval_interval)\n","    plt.plot(steps, returns)\n","    plt.ylabel('Average Return')\n","    plt.xlabel('Step')\n","    plt.ylim(top=870)\n","\n","    train_checkpointer.save(tf_agent.train_step_counter.numpy())\n","    #rb_checkpointer.save(global_step)\n","    \n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUlguwwVwQ9k","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688385,"user_tz":300,"elapsed":8465,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def self_play_train_ppo(tf_agent, train_env, eval_env, train_checkpointer, replay_buffer):\n","  \"\"\"GPUs = GPU.getGPUs()\n","  gpu = GPUs[0]\n","  def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","  printm()\"\"\"\n","  def construct_intended_action(policy0, policy1, time_step):\n","    return pgg.construct_intended_action(policy0, policy1, time_step)\n","  \n","  def compute_avg_return(environment, policy0, policy1, num_episodes=10):\n","\n","    total_return = 0.0\n","    for _ in range(num_episodes):\n","\n","      time_step = environment.reset()\n","      episode_return = 0.0\n","\n","      while not time_step.is_last():\n","        new_action, _, _ = construct_intended_action(policy0, policy1, time_step)\n","        action_step = ps.PolicyStep(action=new_action)\n","\n","        time_step = environment.step(action_step.action)\n","        \n","        episode_return += time_step.reward\n","      total_return += episode_return\n","\n","    avg_return = total_return / num_episodes\n","    return avg_return.numpy()[0]\n","\n","\n","  \"\"\"rb_checkpointer = common.Checkpointer(\n","        ckpt_dir=os.path.join(tempdir, 'replay_buffer'),\n","        max_to_keep=1,\n","        replay_buffer=replay_buffer)\"\"\"\n","  \n","  \"\"\"upload_and_unzip_file_to(os.path.join(tempdir, 'replay_buffer'))\n","  rb_checkpointer.initialize_or_restore()\"\"\"\n","  \n","  def collect_episode(environment, policy0, policy1, num_episodes):\n","\n","    episode_counter = 0\n","    environment.reset()\n","    while episode_counter < num_episodes:\n","      time_step = environment.current_time_step()\n","\n","\n","      new_action, state, info = construct_intended_action(policy0, policy1, time_step)\n","      action_step = ps.PolicyStep(action=new_action, state=state, info=info)\n","\n","\n","      next_time_step = environment.step(action_step.action)\n","\n","      traj = trajectory.from_transition(time_step, action_step, next_time_step) #expand \n","\n","      # Add trajectory to the replay buffer\n","      replay_buffer.add_batch(traj)\n","\n","      if traj.is_boundary():\n","        episode_counter += 1\n","\n","\n","  \n","  with tf.device('/device:GPU:0'):\n","    try:\n","      %%time\n","    except:\n","      pass\n","\n","    # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n","    tf_agent.train = common.function(tf_agent.train)\n","\n","    # Reset the train step\n","    tf_agent.train_step_counter.assign(0)\n","\n","    # Evaluate the agent's policy once before training.\n","    avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","    returns = [avg_return]\n","\n","    for _ in range(num_iterations):\n","\n","      # Collect a few episodes using collect_policy and save to the replay buffer.\n","      collect_episode(\n","          train_env, tf_agent.collect_policy, tf_agent.collect_policy, collect_episodes_per_iteration)\n","\n","      # Use data from the buffer and update the agent's network.\n","      experience = replay_buffer.gather_all()\n","      train_loss = tf_agent.train(experience)\n","      replay_buffer.clear()\n","\n","      step = tf_agent.train_step_counter.numpy()\n","\n","      if step % log_interval == 0:\n","        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n","\n","      if step % eval_interval == 0:\n","        avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n","        returns.append(avg_return)\n","\n","\n","    steps = range(0, (num_iterations + 1)*5, eval_interval)\n","    plt.plot(steps, returns)\n","    plt.ylabel('Average Return')\n","    plt.xlabel('Step')\n","    plt.ylim(top=1)\n","\n","    train_checkpointer.save(tf_agent.train_step_counter.numpy())\n","    #rb_checkpointer.save(global_step)\n","    \n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"-agaXo6mCpFQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688387,"user_tz":300,"elapsed":7964,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def get_checkpoint_name(fname):\n","  return \"gdrive/My Drive/colab+git/\"+fname+\"-cp\"\n","def save_checkpoint(fname, checkpoint_dir, train_checkpointer, rb_checkpointer):\n","  train_checkpointer.save(tf.compat.v1.train.get_or_create_global_step())\n","  checkpoint_zip_filename = create_zip_file(checkpoint_dir, os.path.join(tempdir, fname + '-cp'))\n","  #rb_checkpoint_zip_filename = create_zip_file(os.path.join(tempdir, 'replay_buffer'), os.path.join(tempdir, fname + '-rb'))\n","  %pwd\n","  nm = get_checkpoint_name(fname)\n","  os.mkdir(nm)\n","\n","  shutil.move(checkpoint_zip_filename, nm)\n","  #shutil.move(checkpoint_zip_filename, \"gdrive/My Drive/colab+git/\"+fname+\"-rb\")\n","\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNYUOrNtItrM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688698,"user_tz":300,"elapsed":7667,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def unzip_cp(checkpoint_dir, fname, train_checkpointer):\n","  #checkpoint_dir = checkpoint_dir in fname\n","  train_checkpointer.save(tf_agent.train_step_counter.numpy())\n","  nm = get_checkpoint_name(fname)\n","  fl = os.path.join(nm, fname + \"-cp.zip\")\n","  with zipfile.ZipFile(fl, 'r') as zip:\n","    k = zip.extractall(path=checkpoint_dir)\n","    zip.close()\n","  train_checkpointer.initialize_or_restore()\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"wK7VUcDknNCT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688700,"user_tz":300,"elapsed":6681,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def save_policy(tf_agent, fname):\n","  policy_dir = os.path.join(tempdir, 'policy')\n","  saver = policy_saver.PolicySaver(tf_agent.policy, batch_size=None)\n","  saver.save(policy_dir)\n","\n","  policy_zip_filename = create_zip_file(policy_dir, os.path.join(tempdir, fname + '-p'))\n","  #rb_checkpoint_zip_filename = create_zip_file(os.path.join(tempdir, 'replay_buffer'), os.path.join(tempdir, fname + '-rb'))\n","  %pwd\n","  nm = get_policy_dir_name(fname)\n","  os.mkdir(nm)\n","\n","  shutil.move(policy_zip_filename, nm)\n","  #shutil.move(checkpoint_zip_filename, \"gdrive/My Drive/colab+git/\"+fname+\"-rb\")\n","\n","def get_policy_dir_name(fname):\n","  return \"gdrive/My Drive/colab+git/\"+fname+\"-cp/p\"\n","def get_policy_name(fname):\n","  dir = get_policy_dir_name(fname)\n","  return dir + \"/\" + fname + \"-p.zip\"\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUDWRT9sla6m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688701,"user_tz":300,"elapsed":6467,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["import pandas as pd\n","def construct_play_action(new_action):\n","  if type(new_action) is tuple:\n","    p, _, _ = new_action\n","    new_action = p\n","  return new_action\n","\n","def play_self(policy, environment):\n","  ret = []\n","  done = False\n","  time_step = environment.reset()\n","\n","  while not done:\n","    time_step = environment.current_time_step()\n","    #print(time_step.observation)\n","    #print(policy0.distribution(time_step))\n","\n","    new_action = pgg.construct_intended_action(policy, policy, time_step)\n","    new_action = construct_play_action(new_action)\n","    #print(new_action)\n","    act = new_action.numpy()[0]\n","    action_step = ps.PolicyStep(action=new_action)\n","\n","\n","    next_time_step = environment.step(action_step.action)\n","\n","    traj = trajectory.from_transition(time_step, action_step, next_time_step) #expand \n","    if traj.is_boundary():\n","      done = True\n","      return time_step.observation.numpy()\n","\n","def play_fixed_action(policy, action, environment):\n","  ret = []\n","  done = False\n","  time_step = environment.reset()\n","\n","  while not done:\n","    time_step = environment.current_time_step()\n","\n","    new_action = pgg.construct_fixed_action(policy, action, time_step)\n","    new_action = construct_play_action(new_action)\n","\n","    act = new_action.numpy()[0]\n","    action_step = ps.PolicyStep(action=new_action)\n","\n","    next_time_step = environment.step(action_step.action)\n","\n","    traj = trajectory.from_transition(time_step, action_step, next_time_step) #expand \n","    if traj.is_boundary():\n","      done = True\n","      return time_step.observation.numpy()\n","\n","def play_tit_for_tat(policy, environment):\n","  ret = []\n","  done = False\n","  time_step = environment.reset()\n","  prev_act = 1\n","\n","  while not done:\n","    time_step = environment.current_time_step()\n","\n","    new_action = pgg.construct_fixed_action(policy, prev_act, time_step)\n","    new_action = construct_play_action(new_action)\n","\n","    act = new_action.numpy()[0]\n","    prev_act = new_action[0].numpy()[0]\n","    action_step = ps.PolicyStep(action=new_action)\n","\n","    next_time_step = environment.step(action_step.action)\n","\n","    traj = trajectory.from_transition(time_step, action_step, next_time_step) #expand \n","    if traj.is_boundary():\n","      done = True\n","      #print(time_step.reward)\n","      return time_step.observation.numpy()\n","\n","def add_graph(graph, obs):\n","  r, c = np.shape(obs)\n","  for i in range(r):\n","    graph[i].append(obs[i][0])\n","\n","def create_empty_graph():\n","  ret = []\n","  for i in range(12):\n","    ret.append([])\n","  return ret\n","\n","def eval_returns(checkpoint_dir, fname, train_checkpointer, eval_env, policy):\n","\n","\n","  self_graph = create_empty_graph()\n","  coop_graph = create_empty_graph()\n","  defect_graph = create_empty_graph()\n","  tft_graph = create_empty_graph()\n","  fixed_game_returns = np.array(range(4), dtype=object)\n","  s1 = 0\n","  s2 = 0\n","  s3 = 0\n","  s4 = 0\n","\n","\n","  for _ in range(eval_returns_amt):\n","    self_g = play_self(policy, eval_env)[0]\n","    #print(self_g)\n","    s1 += reward_fun(self_g[11][0], self_g[11][1])\n","    add_graph(self_graph, self_g)\n","\n","    nc = (play_fixed_action(policy, 1, eval_env))[0]\n","    #print(nc)\n","    s2 += reward_fun(nc[11][0], nc[11][1])\n","    add_graph(coop_graph, nc)\n","\n","    nd = (play_fixed_action(policy, 0, eval_env))[0]\n","    #print(nd)\n","    s3 += reward_fun(nd[11][0], nd[11][1])\n","    add_graph(defect_graph, nd)\n","\n","    nt = (play_tit_for_tat(policy, eval_env))[0]\n","    #print(nt)\n","    s4 += reward_fun(nt[11][0], nt[11][1])\n","    add_graph(tft_graph, nt)\n","\n","\n","  fixed_game_returns[0] = s1/100\n","  fixed_game_returns[1] = s2/100\n","  fixed_game_returns[2] = s3/100\n","  fixed_game_returns[3] = s4/100\n","\n","  nm = \"gdrive/My Drive/colab+git/fixed_data\"\n","  os.mkdir(os.path.join(nm, fname))\n","  np.savetxt(os.path.join(nm, fname+\"/fixed_game_returns.csv\"), fixed_game_returns)\n","  print('self', 'cooperate', 'defect', 'tit-for-tat', fixed_game_returns)\n","  fig, axs = plt.subplots(4, sharex=True, sharey=True)\n","\n","\n","  data0 = np.transpose(np.array(self_graph))\n","  np.savetxt(os.path.join(nm, fname+\"/self_graph.csv\"), data0)\n","  axs[0].set_title('self')\n","  axs[0].boxplot(data0[:,:-1])\n","\n","  data1 = np.transpose(np.array(coop_graph))\n","  np.savetxt(os.path.join(nm, fname+\"/coop_graph.csv\"), data1)\n","  axs[1].set_title('coop')\n","  axs[1].boxplot(data1[:,:-1])\n","\n","  data2 = np.transpose(np.array(defect_graph))\n","  np.savetxt(os.path.join(nm, fname+\"/defect_graph.csv\"), data2)\n","  axs[2].set_title('defect')\n","  axs[2].boxplot(data2[:,:-1])\n","\n","  data3 = np.transpose(np.array(tft_graph))\n","  np.savetxt(os.path.join(nm, fname+\"/tft_graph.csv\"), data3)\n","  axs[3].set_title('tft')\n","  axs[3].boxplot(data3[:,:-1])\n","\n","  plt.show()\n","\n","def make_graphs(dirname):\n","  nm = \"gdrive/My Drive/colab+git/fixed_data/\"+dirname\n","  fixed_game_returns = np.loadtxt(os.path.join(nm, \"fixed_game_returns.csv\"))\n","  self_graph = np.loadtxt(os.path.join(nm, \"self_graph.csv\"))\n","  coop_graph = np.loadtxt(os.path.join(nm, \"coop_graph.csv\"))\n","  defect_graph = np.loadtxt(os.path.join(nm, \"defect_graph.csv\"))\n","  tft_graph = np.loadtxt(os.path.join(nm, \"tft_graph.csv\"))\n","  print('self', 'cooperate', 'defect', 'tit-for-tat', fixed_game_returns)\n","  fig, axs = plt.subplots(4, sharex=True, sharey=True)\n","  axs[0].set_title('self')\n","  axs[0].boxplot(self_graph[:,:-1])\n","  axs[1].set_title('coop')\n","  axs[1].boxplot(coop_graph[:,:-1])\n","  axs[2].set_title('defect')\n","  axs[2].boxplot(defect_graph[:,:-1])\n","  axs[3].set_title('tft')\n","  axs[3].boxplot(tft_graph[:,:-1])\n","\n","\n","\n","\n","def eval_returns_no_save(checkpoint_dir, fname, train_checkpointer, eval_env, policy):\n","\n","\n","  self_graph = create_empty_graph()\n","  coop_graph = create_empty_graph()\n","  defect_graph = create_empty_graph()\n","  tft_graph = create_empty_graph()\n","  fixed_game_returns = np.array(range(4), dtype=object)\n","  s1 = 0\n","  s2 = 0\n","  s3 = 0\n","  s4 = 0\n","\n","\n","  for _ in range(int(eval_returns_amt)):\n","    self_g = play_self(policy, eval_env)[0]\n","    #print(self_g)\n","    s1 += reward_fun(self_g[11][0], self_g[11][1])\n","    add_graph(self_graph, self_g)\n","\n","    nc = (play_fixed_action(policy, 1, eval_env))[0]\n","    #print(nc)\n","    s2 += reward_fun(nc[11][0], nc[11][1])\n","    add_graph(coop_graph, nc)\n","\n","    nd = (play_fixed_action(policy, 0, eval_env))[0]\n","    #print(nd)\n","    s3 += reward_fun(nd[11][0], nd[11][1])\n","    add_graph(defect_graph, nd)\n","\n","    nt = (play_tit_for_tat(policy, eval_env))[0]\n","    #print(nt)\n","    s4 += reward_fun(nt[11][0], nt[11][1])\n","    add_graph(tft_graph, nt)\n","\n","\n","  fixed_game_returns[0] = s1/100\n","  fixed_game_returns[1] = s2/100\n","  fixed_game_returns[2] = s3/100\n","  fixed_game_returns[3] = s4/100\n","\n","  nm = \"gdrive/My Drive/colab+git/fixed_data\"\n","  print('self', 'cooperate', 'defect', 'tit-for-tat', fixed_game_returns)\n","  fig, axs = plt.subplots(4, sharex=True, sharey=True)\n","\n","\n","  data0 = np.transpose(np.array(self_graph))\n","  axs[0].set_title('self')\n","  axs[0].boxplot(data0[:,:-1])\n","\n","  data1 = np.transpose(np.array(coop_graph))\n","  axs[1].set_title('coop')\n","  axs[1].boxplot(data1[:,:-1])\n","\n","  data2 = np.transpose(np.array(defect_graph))\n","  axs[2].set_title('defect')\n","  axs[2].boxplot(data2[:,:-1])\n","\n","  data3 = np.transpose(np.array(tft_graph))\n","  axs[3].set_title('tft')\n","  axs[3].boxplot(data3[:,:-1])\n","\n","  plt.show()\n","\n","\n","\n","\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcugAxkxL2rH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747688702,"user_tz":300,"elapsed":5958,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def extract_policy(nm):\n","  with zipfile.ZipFile(nm, 'r') as zip:\n","    zip.extractall(path=nm[:-4])\n","    zip.close()\n","    return tf.compat.v2.saved_model.load(nm[:-4])\n","def league(dirnames):\n","  with tf.device('/device:GPU:0'):\n","    policies = []\n","\n","    for i in range(len(dirnames)):\n","\n","        #os.mkdir(fnames[i][50:-4])\n","        \n","        policies.append(extract_policy(dirnames[i]))\n","\n","\n","    try:\n","      %%time\n","    except:\n","      pass\n","\n","    # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n","    tf_agent.train = common.function(tf_agent.train)\n","\n","    # Reset the train step\n","    tf_agent.train_step_counter.assign(0)\n","\n","    # Evaluate the agent's policy once before training.\n","    avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","    returns = [avg_return]\n","\n","    for u in range(100):\n","      rand_op = random.randint(0, len(dirnames))\n","\n","      print(rand_op)\n","\n","      pol = None\n","      if rand_op == current_train:\n","        pol = tf_agent.collect_policy\n","      else:\n","        pol = policies[rand_op]\n","\n","      for _ in range(num_iterations):\n","        # Collect a few episodes using collect_policy and save to the replay buffer.\n","        collect_episode(\n","            train_env, tf_agent.collect_policy, pol, collect_episodes_per_iteration, replay_buffer)\n","\n","        # Use data from the buffer and update the agent's network.\n","        experience = replay_buffer.gather_all()\n","        train_loss = tf_agent.train(experience)\n","        replay_buffer.clear()\n","\n","        step = tf_agent.train_step_counter.numpy()\n","\n","        if step % log_interval == 0:\n","          print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n","\n","        if step % eval_interval == 0:\n","          avg_return = compute_avg_return(eval_env, tf_agent.policy, pol, num_eval_episodes)\n","          print('step = {0}: Average Return = {1}'.format(step, avg_return))\n","          returns.append(avg_return)\n","      steps = range(0, (num_iterations + 1)*5, eval_interval)\n","      plt.plot(steps, returns[-(len(steps)):])\n","      plt.ylabel('Average Return')\n","      plt.xlabel('Step')\n","      plt.ylim(top=1600)\n","\n","  \n","\n","\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wgKdwYGMLM0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596747693199,"user_tz":300,"elapsed":10203,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["checkpoint_dir = os.path.join(tempdir, fname)\n","env = create_env()\n","action_spec = array_spec.BoundedArraySpec(\n","    shape=(1,), dtype=np.float32, minimum=0, maximum=1, name='action')\n","tf_agent = construct_ppo_agent(env.observation_spec(), action_spec, env.time_step_spec())\n","replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","    data_spec=tf_agent.collect_data_spec,\n","    batch_size=env.batch_size,\n","    max_length=replay_buffer_capacity)\n","tc = make_checkpoint(tf_agent, env, checkpoint_dir, replay_buffer)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBkmW9cQC2tG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1596747702270,"user_tz":300,"elapsed":18999,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"224f0fc0-51cb-43d7-a415-ee9adda5a4aa"},"source":["make_graphs(\"svo-000-ppo-pgg-2\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["self cooperate defect tit-for-tat [1.         3.87329459 1.         1.75      ]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"zM524_9z1DA_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1596751828632,"user_tz":300,"elapsed":4143953,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"84bbb1c4-0798-4a5b-a349-84893fed79c7"},"source":["self_play_train_ppo(tf_agent, env, create_env(), tc, replay_buffer)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["CPU times: user 2 Âµs, sys: 0 ns, total: 2 Âµs\n","Wall time: 5.96 Âµs\n","step = 10: loss = 402.58709716796875\n","step = 10: Average Return = -2.6794893741607666\n","step = 20: loss = 407.927978515625\n","step = 20: Average Return = -2.218820810317993\n","step = 30: loss = 243.23081970214844\n","step = 30: Average Return = -0.9387072324752808\n","step = 40: loss = 156.97164916992188\n","step = 40: Average Return = -0.17054954171180725\n","step = 50: loss = 158.13780212402344\n","step = 50: Average Return = -0.01692304015159607\n","step = 60: loss = 138.02020263671875\n","step = 60: Average Return = -0.0026965439319610596\n","step = 70: loss = 75.531494140625\n","step = 70: Average Return = -0.0017413944005966187\n","step = 80: loss = 106.65309143066406\n","step = 80: Average Return = -0.000900954008102417\n","step = 90: loss = 211.0922393798828\n","step = 90: Average Return = -0.0008583813905715942\n","step = 100: loss = 95.66264343261719\n","step = 100: Average Return = -0.0007521063089370728\n","step = 110: loss = 181.48760986328125\n","step = 110: Average Return = -0.0007211416959762573\n","step = 120: loss = 106.91483306884766\n","step = 120: Average Return = -0.0004187077283859253\n","step = 130: loss = 134.75152587890625\n","step = 130: Average Return = -0.00022986531257629395\n","step = 140: loss = 92.49278259277344\n","step = 140: Average Return = -0.0001465529203414917\n","step = 150: loss = 101.86675262451172\n","step = 150: Average Return = -8.697807788848877e-05\n","step = 160: loss = 57.78456115722656\n","step = 160: Average Return = -0.00010135769844055176\n","step = 170: loss = 100.19806671142578\n","step = 170: Average Return = -0.00013831257820129395\n","step = 180: loss = 62.336978912353516\n","step = 180: Average Return = -0.0001665055751800537\n","step = 190: loss = 149.77056884765625\n","step = 190: Average Return = -0.00024211406707763672\n","step = 200: loss = 139.88446044921875\n","step = 200: Average Return = -0.00029499828815460205\n","step = 210: loss = 74.10951232910156\n","step = 210: Average Return = -0.00027742981910705566\n","step = 220: loss = 101.9432144165039\n","step = 220: Average Return = -0.00026585161685943604\n","step = 230: loss = 110.87720489501953\n","step = 230: Average Return = -0.0002014636993408203\n","step = 240: loss = 102.90113830566406\n","step = 240: Average Return = -0.00018656253814697266\n","step = 250: loss = 68.90939331054688\n","step = 250: Average Return = -0.0001876354217529297\n","step = 260: loss = 48.89208221435547\n","step = 260: Average Return = -0.00015494227409362793\n","step = 270: loss = 138.78729248046875\n","step = 270: Average Return = -0.0001649707555770874\n","step = 280: loss = 82.5650405883789\n","step = 280: Average Return = -0.00017999112606048584\n","step = 290: loss = 93.82798767089844\n","step = 290: Average Return = -0.00021973252296447754\n","step = 300: loss = 86.12537384033203\n","step = 300: Average Return = -0.0002648979425430298\n","step = 310: loss = 105.8930435180664\n","step = 310: Average Return = -0.0003059804439544678\n","step = 320: loss = 178.17735290527344\n","step = 320: Average Return = -0.0002855360507965088\n","step = 330: loss = 214.1913299560547\n","step = 330: Average Return = -0.00031016767024993896\n","step = 340: loss = 124.68782806396484\n","step = 340: Average Return = -0.000341072678565979\n","step = 350: loss = 102.23997497558594\n","step = 350: Average Return = -0.000280037522315979\n","step = 360: loss = 57.29261779785156\n","step = 360: Average Return = -0.0002675652503967285\n","step = 370: loss = 169.47996520996094\n","step = 370: Average Return = -0.00023812055587768555\n","step = 380: loss = 147.9275360107422\n","step = 380: Average Return = -0.00031293928623199463\n","step = 390: loss = 62.502742767333984\n","step = 390: Average Return = -0.00026911497116088867\n","step = 400: loss = 107.62247467041016\n","step = 400: Average Return = -0.0002079010009765625\n","step = 410: loss = 230.92300415039062\n","step = 410: Average Return = -0.0001571178436279297\n","step = 420: loss = 176.9434356689453\n","step = 420: Average Return = -0.00011850893497467041\n","step = 430: loss = 83.99476623535156\n","step = 430: Average Return = -0.00010436773300170898\n","step = 440: loss = 104.29383087158203\n","step = 440: Average Return = -0.00010827183723449707\n","step = 450: loss = 158.52203369140625\n","step = 450: Average Return = -8.828938007354736e-05\n","step = 460: loss = 167.56300354003906\n","step = 460: Average Return = -7.319450378417969e-05\n","step = 470: loss = 160.0305938720703\n","step = 470: Average Return = -7.107853889465332e-05\n","step = 480: loss = 148.22897338867188\n","step = 480: Average Return = -6.344914436340332e-05\n","step = 490: loss = 107.50563049316406\n","step = 490: Average Return = -6.802380084991455e-05\n","step = 500: loss = 105.00086975097656\n","step = 500: Average Return = -7.215142250061035e-05\n","step = 510: loss = 59.749446868896484\n","step = 510: Average Return = -7.463991641998291e-05\n","step = 520: loss = 131.45028686523438\n","step = 520: Average Return = -6.459653377532959e-05\n","step = 530: loss = 99.01559448242188\n","step = 530: Average Return = -6.602704524993896e-05\n","step = 540: loss = 201.7116241455078\n","step = 540: Average Return = -6.318092346191406e-05\n","step = 550: loss = 136.1942596435547\n","step = 550: Average Return = -8.037686347961426e-05\n","step = 560: loss = 183.54795837402344\n","step = 560: Average Return = -7.806718349456787e-05\n","step = 570: loss = 117.70478820800781\n","step = 570: Average Return = -7.764995098114014e-05\n","step = 580: loss = 129.97471618652344\n","step = 580: Average Return = -7.423758506774902e-05\n","step = 590: loss = 137.57540893554688\n","step = 590: Average Return = -6.876885890960693e-05\n","step = 600: loss = 136.3114776611328\n","step = 600: Average Return = -6.192922592163086e-05\n","step = 610: loss = 271.1534729003906\n","step = 610: Average Return = -5.529820919036865e-05\n","step = 620: loss = 65.77616882324219\n","step = 620: Average Return = -4.775822162628174e-05\n","step = 630: loss = 123.6705551147461\n","step = 630: Average Return = -5.263090133666992e-05\n","step = 640: loss = 159.2216033935547\n","step = 640: Average Return = -5.2422285079956055e-05\n","step = 650: loss = 132.89764404296875\n","step = 650: Average Return = -5.397200584411621e-05\n","step = 660: loss = 87.93769073486328\n","step = 660: Average Return = -5.2809715270996094e-05\n","step = 670: loss = 91.7259521484375\n","step = 670: Average Return = -5.7637691497802734e-05\n","step = 680: loss = 109.48561096191406\n","step = 680: Average Return = -5.824863910675049e-05\n","step = 690: loss = 106.90467834472656\n","step = 690: Average Return = -5.647540092468262e-05\n","step = 700: loss = 185.0579071044922\n","step = 700: Average Return = -4.2304396629333496e-05\n","step = 710: loss = 67.45085906982422\n","step = 710: Average Return = -3.878772258758545e-05\n","step = 720: loss = 149.2091522216797\n","step = 720: Average Return = -3.491342067718506e-05\n","step = 730: loss = 89.32791900634766\n","step = 730: Average Return = -3.2141804695129395e-05\n","step = 740: loss = 46.708656311035156\n","step = 740: Average Return = -3.406405448913574e-05\n","step = 750: loss = 122.55540466308594\n","step = 750: Average Return = -2.9996037483215332e-05\n","step = 760: loss = 244.11985778808594\n","step = 760: Average Return = -2.8967857360839844e-05\n","step = 770: loss = 145.78793334960938\n","step = 770: Average Return = -2.606213092803955e-05\n","step = 780: loss = 150.5380859375\n","step = 780: Average Return = -2.5406479835510254e-05\n","step = 790: loss = 56.80531311035156\n","step = 790: Average Return = -2.606213092803955e-05\n","step = 800: loss = 156.8148956298828\n","step = 800: Average Return = -2.8327107429504395e-05\n","step = 810: loss = 185.40908813476562\n","step = 810: Average Return = -2.7865171432495117e-05\n","step = 820: loss = 47.790042877197266\n","step = 820: Average Return = -2.3037195205688477e-05\n","step = 830: loss = 91.70267486572266\n","step = 830: Average Return = -2.09808349609375e-05\n","step = 840: loss = 90.37584686279297\n","step = 840: Average Return = -2.1636486053466797e-05\n","step = 850: loss = 119.60338592529297\n","step = 850: Average Return = -2.117455005645752e-05\n","step = 860: loss = 78.0875244140625\n","step = 860: Average Return = -2.212822437286377e-05\n","step = 870: loss = 79.6517333984375\n","step = 870: Average Return = -2.1472573280334473e-05\n","step = 880: loss = 97.65723419189453\n","step = 880: Average Return = -2.212822437286377e-05\n","step = 890: loss = 136.97091674804688\n","step = 890: Average Return = -2.3618340492248535e-05\n","step = 900: loss = 76.14276885986328\n","step = 900: Average Return = -2.3111701011657715e-05\n","step = 910: loss = 98.3277587890625\n","step = 910: Average Return = -2.5570392608642578e-05\n","step = 920: loss = 91.19598388671875\n","step = 920: Average Return = -2.6881694793701172e-05\n","step = 930: loss = 98.7773666381836\n","step = 930: Average Return = -2.7373433113098145e-05\n","step = 940: loss = 122.23343658447266\n","step = 940: Average Return = -2.6881694793701172e-05\n","step = 950: loss = 112.92387390136719\n","step = 950: Average Return = -2.8684735298156738e-05\n","step = 960: loss = 103.39373779296875\n","step = 960: Average Return = -2.746284008026123e-05\n","step = 970: loss = 94.86441040039062\n","step = 970: Average Return = -3.0487775802612305e-05\n","step = 980: loss = 222.7903594970703\n","step = 980: Average Return = -2.9012560844421387e-05\n","step = 990: loss = 92.0846176147461\n","step = 990: Average Return = -2.9414892196655273e-05\n","step = 1000: loss = 83.2431869506836\n","step = 1000: Average Return = -2.7373433113098145e-05\n","step = 1010: loss = 85.77967071533203\n","step = 1010: Average Return = -2.524256706237793e-05\n","step = 1020: loss = 119.55986785888672\n","step = 1020: Average Return = -2.625584602355957e-05\n","step = 1030: loss = 99.57283020019531\n","step = 1030: Average Return = -2.4750828742980957e-05\n","step = 1040: loss = 196.3683624267578\n","step = 1040: Average Return = -2.212822437286377e-05\n","step = 1050: loss = 123.47599792480469\n","step = 1050: Average Return = -2.065300941467285e-05\n","step = 1060: loss = 162.6065673828125\n","step = 1060: Average Return = -2.0101666450500488e-05\n","step = 1070: loss = 129.20762634277344\n","step = 1070: Average Return = -1.9669532775878906e-05\n","step = 1080: loss = 119.06983947753906\n","step = 1080: Average Return = -1.8849968910217285e-05\n","step = 1090: loss = 90.38347625732422\n","step = 1090: Average Return = -1.5243887901306152e-05\n","step = 1100: loss = 70.92191314697266\n","step = 1100: Average Return = -1.3932585716247559e-05\n","step = 1110: loss = 90.68807983398438\n","step = 1110: Average Return = -1.4588236808776855e-05\n","step = 1120: loss = 76.97523498535156\n","step = 1120: Average Return = -1.360476016998291e-05\n","step = 1130: loss = 110.21200561523438\n","step = 1130: Average Return = -1.2621283531188965e-05\n","step = 1140: loss = 112.66230773925781\n","step = 1140: Average Return = -1.3276934623718262e-05\n","step = 1150: loss = 163.94757080078125\n","step = 1150: Average Return = -1.3440847396850586e-05\n","step = 1160: loss = 151.32989501953125\n","step = 1160: Average Return = -1.3515353202819824e-05\n","step = 1170: loss = 219.95291137695312\n","step = 1170: Average Return = -1.5407800674438477e-05\n","step = 1180: loss = 117.01771545410156\n","step = 1180: Average Return = -1.6063451766967773e-05\n","step = 1190: loss = 108.34046173095703\n","step = 1190: Average Return = -1.4647841453552246e-05\n","step = 1200: loss = 60.837554931640625\n","step = 1200: Average Return = -1.4096498489379883e-05\n","step = 1210: loss = 151.6563262939453\n","step = 1210: Average Return = -1.245737075805664e-05\n","step = 1220: loss = 76.1699447631836\n","step = 1220: Average Return = -1.3768672943115234e-05\n","step = 1230: loss = 78.42194366455078\n","step = 1230: Average Return = -1.360476016998291e-05\n","step = 1240: loss = 111.56839752197266\n","step = 1240: Average Return = -1.360476016998291e-05\n","step = 1250: loss = 133.6331024169922\n","step = 1250: Average Return = -1.3962388038635254e-05\n","step = 1260: loss = 125.46402740478516\n","step = 1260: Average Return = -1.5735626220703125e-05\n","step = 1270: loss = 104.12234497070312\n","step = 1270: Average Return = -1.4260411262512207e-05\n","step = 1280: loss = 148.61260986328125\n","step = 1280: Average Return = -1.5735626220703125e-05\n","step = 1290: loss = 176.3736572265625\n","step = 1290: Average Return = -1.4588236808776855e-05\n","step = 1300: loss = 152.0419158935547\n","step = 1300: Average Return = -1.3694167137145996e-05\n","step = 1310: loss = 243.16587829589844\n","step = 1310: Average Return = -1.4260411262512207e-05\n","step = 1320: loss = 69.59424591064453\n","step = 1320: Average Return = -1.3440847396850586e-05\n","step = 1330: loss = 91.08077239990234\n","step = 1330: Average Return = -1.2621283531188965e-05\n","step = 1340: loss = 148.6719512939453\n","step = 1340: Average Return = -1.2785196304321289e-05\n","step = 1350: loss = 188.3572998046875\n","step = 1350: Average Return = -1.2278556823730469e-05\n","step = 1360: loss = 121.44921875\n","step = 1360: Average Return = -1.1473894119262695e-05\n","step = 1370: loss = 150.63018798828125\n","step = 1370: Average Return = -1.0818243026733398e-05\n","step = 1380: loss = 132.69076538085938\n","step = 1380: Average Return = -9.998679161071777e-06\n","step = 1390: loss = 128.6192626953125\n","step = 1390: Average Return = -9.506940841674805e-06\n","step = 1400: loss = 112.91239166259766\n","step = 1400: Average Return = -9.506940841674805e-06\n","step = 1410: loss = 118.33157348632812\n","step = 1410: Average Return = -9.506940841674805e-06\n","step = 1420: loss = 157.51344299316406\n","step = 1420: Average Return = -9.179115295410156e-06\n","step = 1430: loss = 109.98028564453125\n","step = 1430: Average Return = -8.687376976013184e-06\n","step = 1440: loss = 68.47013854980469\n","step = 1440: Average Return = -8.687376976013184e-06\n","step = 1450: loss = 116.38370513916016\n","step = 1450: Average Return = -8.359551429748535e-06\n","step = 1460: loss = 192.5846405029297\n","step = 1460: Average Return = -8.52346420288086e-06\n","step = 1470: loss = 77.27250671386719\n","step = 1470: Average Return = -8.195638656616211e-06\n","step = 1480: loss = 130.6959228515625\n","step = 1480: Average Return = -7.867813110351562e-06\n","step = 1490: loss = 69.48081970214844\n","step = 1490: Average Return = -7.212162017822266e-06\n","step = 1500: loss = 126.59717559814453\n","step = 1500: Average Return = -7.37607479095459e-06\n","step = 1510: loss = 43.2428092956543\n","step = 1510: Average Return = -7.867813110351562e-06\n","step = 1520: loss = 107.04237365722656\n","step = 1520: Average Return = -7.37607479095459e-06\n","step = 1530: loss = 94.17276763916016\n","step = 1530: Average Return = -6.556510925292969e-06\n","step = 1540: loss = 156.87384033203125\n","step = 1540: Average Return = -6.22868537902832e-06\n","step = 1550: loss = 74.19892883300781\n","step = 1550: Average Return = -5.900859832763672e-06\n","step = 1560: loss = 136.25466918945312\n","step = 1560: Average Return = -6.064772605895996e-06\n","step = 1570: loss = 187.7951202392578\n","step = 1570: Average Return = -5.409121513366699e-06\n","step = 1580: loss = 117.43756103515625\n","step = 1580: Average Return = -5.409121513366699e-06\n","step = 1590: loss = 63.26537322998047\n","step = 1590: Average Return = -5.736947059631348e-06\n","step = 1600: loss = 82.77452850341797\n","step = 1600: Average Return = -5.736947059631348e-06\n","step = 1610: loss = 151.94894409179688\n","step = 1610: Average Return = -5.736947059631348e-06\n","step = 1620: loss = 97.16548919677734\n","step = 1620: Average Return = -5.900859832763672e-06\n","step = 1630: loss = 116.57898712158203\n","step = 1630: Average Return = -5.409121513366699e-06\n","step = 1640: loss = 242.038818359375\n","step = 1640: Average Return = -5.5730342864990234e-06\n","step = 1650: loss = 155.40890502929688\n","step = 1650: Average Return = -5.900859832763672e-06\n","step = 1660: loss = 84.75300598144531\n","step = 1660: Average Return = -5.617737770080566e-06\n","step = 1670: loss = 153.61276245117188\n","step = 1670: Average Return = -5.245208740234375e-06\n","step = 1680: loss = 131.7873077392578\n","step = 1680: Average Return = -5.409121513366699e-06\n","step = 1690: loss = 77.92176818847656\n","step = 1690: Average Return = -5.245208740234375e-06\n","step = 1700: loss = 117.46660614013672\n","step = 1700: Average Return = -4.9173831939697266e-06\n","step = 1710: loss = 71.08834838867188\n","step = 1710: Average Return = -4.9173831939697266e-06\n","step = 1720: loss = 103.14360046386719\n","step = 1720: Average Return = -5.245208740234375e-06\n","step = 1730: loss = 71.87920379638672\n","step = 1730: Average Return = -5.081295967102051e-06\n","step = 1740: loss = 69.70909881591797\n","step = 1740: Average Return = -5.081295967102051e-06\n","step = 1750: loss = 76.34423065185547\n","step = 1750: Average Return = -5.409121513366699e-06\n","step = 1760: loss = 134.99684143066406\n","step = 1760: Average Return = -5.409121513366699e-06\n","step = 1770: loss = 160.63290405273438\n","step = 1770: Average Return = -5.736947059631348e-06\n","step = 1780: loss = 135.81265258789062\n","step = 1780: Average Return = -5.736947059631348e-06\n","step = 1790: loss = 52.87171173095703\n","step = 1790: Average Return = -5.409121513366699e-06\n","step = 1800: loss = 228.87351989746094\n","step = 1800: Average Return = -5.245208740234375e-06\n","step = 1810: loss = 102.06657409667969\n","step = 1810: Average Return = -5.409121513366699e-06\n","step = 1820: loss = 112.38412475585938\n","step = 1820: Average Return = -6.22868537902832e-06\n","step = 1830: loss = 116.79263305664062\n","step = 1830: Average Return = -5.736947059631348e-06\n","step = 1840: loss = 121.01060485839844\n","step = 1840: Average Return = -6.064772605895996e-06\n","step = 1850: loss = 83.80939483642578\n","step = 1850: Average Return = -5.736947059631348e-06\n","step = 1860: loss = 86.83252716064453\n","step = 1860: Average Return = -5.409121513366699e-06\n","step = 1870: loss = 143.2078399658203\n","step = 1870: Average Return = -5.409121513366699e-06\n","step = 1880: loss = 121.94305419921875\n","step = 1880: Average Return = -5.245208740234375e-06\n","step = 1890: loss = 104.89966583251953\n","step = 1890: Average Return = -5.081295967102051e-06\n","step = 1900: loss = 154.1068115234375\n","step = 1900: Average Return = -5.081295967102051e-06\n","step = 1910: loss = 117.68994903564453\n","step = 1910: Average Return = -5.245208740234375e-06\n","step = 1920: loss = 144.721923828125\n","step = 1920: Average Return = -5.409121513366699e-06\n","step = 1930: loss = 91.49604797363281\n","step = 1930: Average Return = -5.245208740234375e-06\n","step = 1940: loss = 97.67150115966797\n","step = 1940: Average Return = -5.5730342864990234e-06\n","step = 1950: loss = 153.40492248535156\n","step = 1950: Average Return = -5.900859832763672e-06\n","step = 1960: loss = 138.37899780273438\n","step = 1960: Average Return = -6.3925981521606445e-06\n","step = 1970: loss = 86.72637939453125\n","step = 1970: Average Return = -5.736947059631348e-06\n","step = 1980: loss = 100.31625366210938\n","step = 1980: Average Return = -5.5730342864990234e-06\n","step = 1990: loss = 220.9239044189453\n","step = 1990: Average Return = -5.081295967102051e-06\n","step = 2000: loss = 141.7572784423828\n","step = 2000: Average Return = -5.409121513366699e-06\n","step = 2010: loss = 101.53006744384766\n","step = 2010: Average Return = -5.5730342864990234e-06\n","step = 2020: loss = 125.7242431640625\n","step = 2020: Average Return = -5.409121513366699e-06\n","step = 2030: loss = 208.05824279785156\n","step = 2030: Average Return = -5.409121513366699e-06\n","step = 2040: loss = 182.3280029296875\n","step = 2040: Average Return = -5.409121513366699e-06\n","step = 2050: loss = 100.94371032714844\n","step = 2050: Average Return = -5.5730342864990234e-06\n","step = 2060: loss = 69.96635437011719\n","step = 2060: Average Return = -5.736947059631348e-06\n","step = 2070: loss = 75.67615509033203\n","step = 2070: Average Return = -5.5730342864990234e-06\n","step = 2080: loss = 169.54933166503906\n","step = 2080: Average Return = -5.736947059631348e-06\n","step = 2090: loss = 160.381103515625\n","step = 2090: Average Return = -6.064772605895996e-06\n","step = 2100: loss = 109.22415924072266\n","step = 2100: Average Return = -5.900859832763672e-06\n","step = 2110: loss = 86.02338409423828\n","step = 2110: Average Return = -5.736947059631348e-06\n","step = 2120: loss = 68.12532043457031\n","step = 2120: Average Return = -5.409121513366699e-06\n","step = 2130: loss = 53.97550582885742\n","step = 2130: Average Return = -5.409121513366699e-06\n","step = 2140: loss = 92.48484802246094\n","step = 2140: Average Return = -5.245208740234375e-06\n","step = 2150: loss = 85.37197875976562\n","step = 2150: Average Return = -5.5730342864990234e-06\n","step = 2160: loss = 101.99201965332031\n","step = 2160: Average Return = -5.5730342864990234e-06\n","step = 2170: loss = 95.42159271240234\n","step = 2170: Average Return = -5.736947059631348e-06\n","step = 2180: loss = 281.2067565917969\n","step = 2180: Average Return = -5.5730342864990234e-06\n","step = 2190: loss = 135.0599822998047\n","step = 2190: Average Return = -5.5730342864990234e-06\n","step = 2200: loss = 238.99696350097656\n","step = 2200: Average Return = -5.245208740234375e-06\n","step = 2210: loss = 67.8120346069336\n","step = 2210: Average Return = -4.9173831939697266e-06\n","step = 2220: loss = 162.467529296875\n","step = 2220: Average Return = -4.753470420837402e-06\n","step = 2230: loss = 131.90292358398438\n","step = 2230: Average Return = -4.425644874572754e-06\n","step = 2240: loss = 187.408203125\n","step = 2240: Average Return = -4.0978193283081055e-06\n","step = 2250: loss = 99.10707092285156\n","step = 2250: Average Return = -4.0978193283081055e-06\n","step = 2260: loss = 106.40058135986328\n","step = 2260: Average Return = -3.933906555175781e-06\n","step = 2270: loss = 278.17852783203125\n","step = 2270: Average Return = -3.769993782043457e-06\n","step = 2280: loss = 84.00375366210938\n","step = 2280: Average Return = -3.4421682357788086e-06\n","step = 2290: loss = 143.0149383544922\n","step = 2290: Average Return = -3.2782554626464844e-06\n","step = 2300: loss = 140.98599243164062\n","step = 2300: Average Return = -3.4421682357788086e-06\n","step = 2310: loss = 101.6177749633789\n","step = 2310: Average Return = -3.606081008911133e-06\n","step = 2320: loss = 125.1955337524414\n","step = 2320: Average Return = -3.2782554626464844e-06\n","step = 2330: loss = 155.32791137695312\n","step = 2330: Average Return = -2.950429916381836e-06\n","step = 2340: loss = 100.40454864501953\n","step = 2340: Average Return = -2.950429916381836e-06\n","step = 2350: loss = 134.51316833496094\n","step = 2350: Average Return = -2.6226043701171875e-06\n","step = 2360: loss = 55.02843475341797\n","step = 2360: Average Return = -2.6226043701171875e-06\n","step = 2370: loss = 72.98580169677734\n","step = 2370: Average Return = -2.6226043701171875e-06\n","step = 2380: loss = 79.02385711669922\n","step = 2380: Average Return = -2.6226043701171875e-06\n","step = 2390: loss = 77.6776123046875\n","step = 2390: Average Return = -2.6226043701171875e-06\n","step = 2400: loss = 96.78863525390625\n","step = 2400: Average Return = -2.6226043701171875e-06\n","step = 2410: loss = 122.4232406616211\n","step = 2410: Average Return = -2.6226043701171875e-06\n","step = 2420: loss = 152.72792053222656\n","step = 2420: Average Return = -2.6226043701171875e-06\n","step = 2430: loss = 213.60128784179688\n","step = 2430: Average Return = -2.6226043701171875e-06\n","step = 2440: loss = 130.51235961914062\n","step = 2440: Average Return = -2.4586915969848633e-06\n","step = 2450: loss = 214.64398193359375\n","step = 2450: Average Return = -2.6226043701171875e-06\n","step = 2460: loss = 95.00846099853516\n","step = 2460: Average Return = -2.7865171432495117e-06\n","step = 2470: loss = 53.09929275512695\n","step = 2470: Average Return = -2.950429916381836e-06\n","step = 2480: loss = 123.75872802734375\n","step = 2480: Average Return = -2.7865171432495117e-06\n","step = 2490: loss = 121.25695037841797\n","step = 2490: Average Return = -2.7865171432495117e-06\n","step = 2500: loss = 108.20954895019531\n","step = 2500: Average Return = -2.6226043701171875e-06\n","step = 2510: loss = 110.5939712524414\n","step = 2510: Average Return = -2.7865171432495117e-06\n","step = 2520: loss = 69.3880386352539\n","step = 2520: Average Return = -2.6226043701171875e-06\n","step = 2530: loss = 100.57437896728516\n","step = 2530: Average Return = -2.7865171432495117e-06\n","step = 2540: loss = 99.63275909423828\n","step = 2540: Average Return = -2.7865171432495117e-06\n","step = 2550: loss = 73.30207824707031\n","step = 2550: Average Return = -2.6226043701171875e-06\n","step = 2560: loss = 164.78240966796875\n","step = 2560: Average Return = -2.7865171432495117e-06\n","step = 2570: loss = 139.97097778320312\n","step = 2570: Average Return = -2.7865171432495117e-06\n","step = 2580: loss = 73.25816345214844\n","step = 2580: Average Return = -2.7865171432495117e-06\n","step = 2590: loss = 107.37901306152344\n","step = 2590: Average Return = -2.6226043701171875e-06\n","step = 2600: loss = 83.18111419677734\n","step = 2600: Average Return = -2.294778823852539e-06\n","step = 2610: loss = 133.50411987304688\n","step = 2610: Average Return = -2.4586915969848633e-06\n","step = 2620: loss = 159.30487060546875\n","step = 2620: Average Return = -2.4586915969848633e-06\n","step = 2630: loss = 91.00178527832031\n","step = 2630: Average Return = -2.130866050720215e-06\n","step = 2640: loss = 126.86404418945312\n","step = 2640: Average Return = -1.8030405044555664e-06\n","step = 2650: loss = 76.73361206054688\n","step = 2650: Average Return = -1.6391277313232422e-06\n","step = 2660: loss = 92.64751434326172\n","step = 2660: Average Return = -1.475214958190918e-06\n","step = 2670: loss = 50.24612045288086\n","step = 2670: Average Return = -1.475214958190918e-06\n","step = 2680: loss = 71.6489486694336\n","step = 2680: Average Return = -1.475214958190918e-06\n","step = 2690: loss = 154.4307861328125\n","step = 2690: Average Return = -1.475214958190918e-06\n","step = 2700: loss = 120.70285034179688\n","step = 2700: Average Return = -1.475214958190918e-06\n","step = 2710: loss = 271.37109375\n","step = 2710: Average Return = -1.475214958190918e-06\n","step = 2720: loss = 98.2585678100586\n","step = 2720: Average Return = -1.6391277313232422e-06\n","step = 2730: loss = 159.19540405273438\n","step = 2730: Average Return = -1.475214958190918e-06\n","step = 2740: loss = 106.06578063964844\n","step = 2740: Average Return = -1.475214958190918e-06\n","step = 2750: loss = 84.27391815185547\n","step = 2750: Average Return = -1.475214958190918e-06\n","step = 2760: loss = 224.82313537597656\n","step = 2760: Average Return = -1.475214958190918e-06\n","step = 2770: loss = 161.54823303222656\n","step = 2770: Average Return = -1.475214958190918e-06\n","step = 2780: loss = 89.01832580566406\n","step = 2780: Average Return = -1.475214958190918e-06\n","step = 2790: loss = 125.77855682373047\n","step = 2790: Average Return = -1.475214958190918e-06\n","step = 2800: loss = 142.2172088623047\n","step = 2800: Average Return = -1.475214958190918e-06\n","step = 2810: loss = 98.73993682861328\n","step = 2810: Average Return = -1.475214958190918e-06\n","step = 2820: loss = 59.544189453125\n","step = 2820: Average Return = -1.3113021850585938e-06\n","step = 2830: loss = 105.10829162597656\n","step = 2830: Average Return = -1.3113021850585938e-06\n","step = 2840: loss = 178.2118682861328\n","step = 2840: Average Return = -1.3113021850585938e-06\n","step = 2850: loss = 175.51736450195312\n","step = 2850: Average Return = -1.3113021850585938e-06\n","step = 2860: loss = 287.5604248046875\n","step = 2860: Average Return = -1.3113021850585938e-06\n","step = 2870: loss = 104.63172149658203\n","step = 2870: Average Return = -1.1473894119262695e-06\n","step = 2880: loss = 112.71051025390625\n","step = 2880: Average Return = -1.1473894119262695e-06\n","step = 2890: loss = 66.931884765625\n","step = 2890: Average Return = -1.1473894119262695e-06\n","step = 2900: loss = 131.8954620361328\n","step = 2900: Average Return = -1.1473894119262695e-06\n","step = 2910: loss = 114.89472198486328\n","step = 2910: Average Return = -1.1473894119262695e-06\n","step = 2920: loss = 240.676025390625\n","step = 2920: Average Return = -1.1473894119262695e-06\n","step = 2930: loss = 194.32814025878906\n","step = 2930: Average Return = -1.3113021850585938e-06\n","step = 2940: loss = 139.2748260498047\n","step = 2940: Average Return = -1.1473894119262695e-06\n","step = 2950: loss = 105.75624084472656\n","step = 2950: Average Return = -1.1473894119262695e-06\n","step = 2960: loss = 44.645713806152344\n","step = 2960: Average Return = -1.1473894119262695e-06\n","step = 2970: loss = 186.12994384765625\n","step = 2970: Average Return = -1.3113021850585938e-06\n","step = 2980: loss = 288.595458984375\n","step = 2980: Average Return = -1.3113021850585938e-06\n","step = 2990: loss = 176.50131225585938\n","step = 2990: Average Return = -1.3113021850585938e-06\n","step = 3000: loss = 50.14082336425781\n","step = 3000: Average Return = -1.1473894119262695e-06\n","step = 3010: loss = 76.26142883300781\n","step = 3010: Average Return = -1.1473894119262695e-06\n","step = 3020: loss = 165.29087829589844\n","step = 3020: Average Return = -1.1473894119262695e-06\n","step = 3030: loss = 107.4366455078125\n","step = 3030: Average Return = -1.3113021850585938e-06\n","step = 3040: loss = 195.4971466064453\n","step = 3040: Average Return = -1.3113021850585938e-06\n","step = 3050: loss = 150.94004821777344\n","step = 3050: Average Return = -1.1473894119262695e-06\n","step = 3060: loss = 112.69190216064453\n","step = 3060: Average Return = -1.1473894119262695e-06\n","step = 3070: loss = 86.1433334350586\n","step = 3070: Average Return = -1.3113021850585938e-06\n","step = 3080: loss = 101.38645935058594\n","step = 3080: Average Return = -1.3113021850585938e-06\n","step = 3090: loss = 146.10299682617188\n","step = 3090: Average Return = -1.1473894119262695e-06\n","step = 3100: loss = 188.49476623535156\n","step = 3100: Average Return = -1.1473894119262695e-06\n","step = 3110: loss = 116.58533477783203\n","step = 3110: Average Return = -1.3113021850585938e-06\n","step = 3120: loss = 130.8828887939453\n","step = 3120: Average Return = -1.3113021850585938e-06\n","step = 3130: loss = 93.79154968261719\n","step = 3130: Average Return = -1.3113021850585938e-06\n","step = 3140: loss = 185.2554931640625\n","step = 3140: Average Return = -1.3113021850585938e-06\n","step = 3150: loss = 46.51323699951172\n","step = 3150: Average Return = -1.3113021850585938e-06\n","step = 3160: loss = 62.86140823364258\n","step = 3160: Average Return = -1.1473894119262695e-06\n","step = 3170: loss = 190.00357055664062\n","step = 3170: Average Return = -1.1473894119262695e-06\n","step = 3180: loss = 118.6722183227539\n","step = 3180: Average Return = -1.1473894119262695e-06\n","step = 3190: loss = 189.1495361328125\n","step = 3190: Average Return = -1.1473894119262695e-06\n","step = 3200: loss = 134.4563446044922\n","step = 3200: Average Return = -1.1473894119262695e-06\n","step = 3210: loss = 109.96942901611328\n","step = 3210: Average Return = -1.1473894119262695e-06\n","step = 3220: loss = 84.28235626220703\n","step = 3220: Average Return = -1.1473894119262695e-06\n","step = 3230: loss = 182.9325714111328\n","step = 3230: Average Return = -1.1473894119262695e-06\n","step = 3240: loss = 161.14236450195312\n","step = 3240: Average Return = -1.1473894119262695e-06\n","step = 3250: loss = 176.15818786621094\n","step = 3250: Average Return = -9.834766387939453e-07\n","step = 3260: loss = 87.03831481933594\n","step = 3260: Average Return = -9.834766387939453e-07\n","step = 3270: loss = 156.5753936767578\n","step = 3270: Average Return = -9.834766387939453e-07\n","step = 3280: loss = 106.79073333740234\n","step = 3280: Average Return = -9.834766387939453e-07\n","step = 3290: loss = 162.1133270263672\n","step = 3290: Average Return = -9.834766387939453e-07\n","step = 3300: loss = 351.8539123535156\n","step = 3300: Average Return = -9.834766387939453e-07\n","step = 3310: loss = 75.78900909423828\n","step = 3310: Average Return = -9.834766387939453e-07\n","step = 3320: loss = 143.82884216308594\n","step = 3320: Average Return = -9.834766387939453e-07\n","step = 3330: loss = 88.02005004882812\n","step = 3330: Average Return = -1.1473894119262695e-06\n","step = 3340: loss = 167.07887268066406\n","step = 3340: Average Return = -1.1473894119262695e-06\n","step = 3350: loss = 57.19147872924805\n","step = 3350: Average Return = -9.834766387939453e-07\n","step = 3360: loss = 123.29151916503906\n","step = 3360: Average Return = -9.834766387939453e-07\n","step = 3370: loss = 119.52372741699219\n","step = 3370: Average Return = -9.834766387939453e-07\n","step = 3380: loss = 49.35383605957031\n","step = 3380: Average Return = -9.834766387939453e-07\n","step = 3390: loss = 225.9083251953125\n","step = 3390: Average Return = -9.834766387939453e-07\n","step = 3400: loss = 74.17526245117188\n","step = 3400: Average Return = -9.834766387939453e-07\n","step = 3410: loss = 109.6521224975586\n","step = 3410: Average Return = -9.834766387939453e-07\n","step = 3420: loss = 116.34286499023438\n","step = 3420: Average Return = -9.834766387939453e-07\n","step = 3430: loss = 108.8930435180664\n","step = 3430: Average Return = -9.834766387939453e-07\n","step = 3440: loss = 134.10304260253906\n","step = 3440: Average Return = -9.834766387939453e-07\n","step = 3450: loss = 80.13330841064453\n","step = 3450: Average Return = -8.195638656616211e-07\n","step = 3460: loss = 109.3466567993164\n","step = 3460: Average Return = -9.834766387939453e-07\n","step = 3470: loss = 114.15867614746094\n","step = 3470: Average Return = -8.195638656616211e-07\n","step = 3480: loss = 90.16822814941406\n","step = 3480: Average Return = -8.195638656616211e-07\n","step = 3490: loss = 64.91743469238281\n","step = 3490: Average Return = -8.195638656616211e-07\n","step = 3500: loss = 116.29784393310547\n","step = 3500: Average Return = -8.195638656616211e-07\n","step = 3510: loss = 194.53961181640625\n","step = 3510: Average Return = -8.195638656616211e-07\n","step = 3520: loss = 88.82622528076172\n","step = 3520: Average Return = -8.195638656616211e-07\n","step = 3530: loss = 96.09623718261719\n","step = 3530: Average Return = -8.195638656616211e-07\n","step = 3540: loss = 132.1064910888672\n","step = 3540: Average Return = -8.195638656616211e-07\n","step = 3550: loss = 232.70123291015625\n","step = 3550: Average Return = -8.195638656616211e-07\n","step = 3560: loss = 192.84521484375\n","step = 3560: Average Return = -8.195638656616211e-07\n","step = 3570: loss = 156.4136505126953\n","step = 3570: Average Return = -8.195638656616211e-07\n","step = 3580: loss = 63.4893913269043\n","step = 3580: Average Return = -8.195638656616211e-07\n","step = 3590: loss = 145.7554168701172\n","step = 3590: Average Return = -8.195638656616211e-07\n","step = 3600: loss = 134.885009765625\n","step = 3600: Average Return = -8.195638656616211e-07\n","step = 3610: loss = 138.39991760253906\n","step = 3610: Average Return = -8.195638656616211e-07\n","step = 3620: loss = 63.064300537109375\n","step = 3620: Average Return = -8.195638656616211e-07\n","step = 3630: loss = 117.01115417480469\n","step = 3630: Average Return = -8.195638656616211e-07\n","step = 3640: loss = 149.91346740722656\n","step = 3640: Average Return = -8.195638656616211e-07\n","step = 3650: loss = 68.65605163574219\n","step = 3650: Average Return = -8.195638656616211e-07\n","step = 3660: loss = 126.49757385253906\n","step = 3660: Average Return = -8.195638656616211e-07\n","step = 3670: loss = 84.8609619140625\n","step = 3670: Average Return = -6.556510925292969e-07\n","step = 3680: loss = 165.1211700439453\n","step = 3680: Average Return = -6.556510925292969e-07\n","step = 3690: loss = 111.64631652832031\n","step = 3690: Average Return = -6.556510925292969e-07\n","step = 3700: loss = 65.3868408203125\n","step = 3700: Average Return = -4.917383193969727e-07\n","step = 3710: loss = 115.77037048339844\n","step = 3710: Average Return = -6.556510925292969e-07\n","step = 3720: loss = 102.85133361816406\n","step = 3720: Average Return = -6.556510925292969e-07\n","step = 3730: loss = 101.59423828125\n","step = 3730: Average Return = -6.556510925292969e-07\n","step = 3740: loss = 190.67520141601562\n","step = 3740: Average Return = -6.556510925292969e-07\n","step = 3750: loss = 89.3805923461914\n","step = 3750: Average Return = -6.556510925292969e-07\n","step = 3760: loss = 58.882328033447266\n","step = 3760: Average Return = -6.556510925292969e-07\n","step = 3770: loss = 78.00849914550781\n","step = 3770: Average Return = -4.917383193969727e-07\n","step = 3780: loss = 121.54810333251953\n","step = 3780: Average Return = -4.917383193969727e-07\n","step = 3790: loss = 105.47721099853516\n","step = 3790: Average Return = -4.917383193969727e-07\n","step = 3800: loss = 177.30909729003906\n","step = 3800: Average Return = -4.917383193969727e-07\n","step = 3810: loss = 180.4040985107422\n","step = 3810: Average Return = -4.917383193969727e-07\n","step = 3820: loss = 132.36181640625\n","step = 3820: Average Return = -4.917383193969727e-07\n","step = 3830: loss = 77.85295104980469\n","step = 3830: Average Return = -4.917383193969727e-07\n","step = 3840: loss = 64.29248809814453\n","step = 3840: Average Return = -4.917383193969727e-07\n","step = 3850: loss = 95.38489532470703\n","step = 3850: Average Return = -4.917383193969727e-07\n","step = 3860: loss = 160.02760314941406\n","step = 3860: Average Return = -4.917383193969727e-07\n","step = 3870: loss = 84.63648223876953\n","step = 3870: Average Return = -4.917383193969727e-07\n","step = 3880: loss = 165.20399475097656\n","step = 3880: Average Return = -4.917383193969727e-07\n","step = 3890: loss = 84.32791900634766\n","step = 3890: Average Return = -4.917383193969727e-07\n","step = 3900: loss = 126.38001251220703\n","step = 3900: Average Return = -4.917383193969727e-07\n","step = 3910: loss = 144.0938262939453\n","step = 3910: Average Return = -4.917383193969727e-07\n","step = 3920: loss = 89.44087982177734\n","step = 3920: Average Return = -4.917383193969727e-07\n","step = 3930: loss = 134.6661376953125\n","step = 3930: Average Return = -4.917383193969727e-07\n","step = 3940: loss = 169.38162231445312\n","step = 3940: Average Return = -4.917383193969727e-07\n","step = 3950: loss = 163.52984619140625\n","step = 3950: Average Return = -4.917383193969727e-07\n","step = 3960: loss = 108.74755859375\n","step = 3960: Average Return = -4.917383193969727e-07\n","step = 3970: loss = 121.49666595458984\n","step = 3970: Average Return = -4.917383193969727e-07\n","step = 3980: loss = 72.98419189453125\n","step = 3980: Average Return = -4.917383193969727e-07\n","step = 3990: loss = 79.29328918457031\n","step = 3990: Average Return = -4.917383193969727e-07\n","step = 4000: loss = 136.977783203125\n","step = 4000: Average Return = -4.917383193969727e-07\n","step = 4010: loss = 218.82302856445312\n","step = 4010: Average Return = -4.917383193969727e-07\n","step = 4020: loss = 161.81411743164062\n","step = 4020: Average Return = -4.917383193969727e-07\n","step = 4030: loss = 156.96253967285156\n","step = 4030: Average Return = -4.917383193969727e-07\n","step = 4040: loss = 90.09994506835938\n","step = 4040: Average Return = -4.917383193969727e-07\n","step = 4050: loss = 64.38827514648438\n","step = 4050: Average Return = -4.917383193969727e-07\n","step = 4060: loss = 85.44496154785156\n","step = 4060: Average Return = -4.917383193969727e-07\n","step = 4070: loss = 97.6056900024414\n","step = 4070: Average Return = -4.917383193969727e-07\n","step = 4080: loss = 136.55955505371094\n","step = 4080: Average Return = -4.917383193969727e-07\n","step = 4090: loss = 70.28958892822266\n","step = 4090: Average Return = -4.917383193969727e-07\n","step = 4100: loss = 133.3074188232422\n","step = 4100: Average Return = -4.917383193969727e-07\n","step = 4110: loss = 57.608177185058594\n","step = 4110: Average Return = -4.917383193969727e-07\n","step = 4120: loss = 150.44671630859375\n","step = 4120: Average Return = -4.917383193969727e-07\n","step = 4130: loss = 57.911739349365234\n","step = 4130: Average Return = -4.917383193969727e-07\n","step = 4140: loss = 208.23977661132812\n","step = 4140: Average Return = -4.917383193969727e-07\n","step = 4150: loss = 107.73628997802734\n","step = 4150: Average Return = -4.917383193969727e-07\n","step = 4160: loss = 79.47792053222656\n","step = 4160: Average Return = -4.917383193969727e-07\n","step = 4170: loss = 89.24712371826172\n","step = 4170: Average Return = -4.917383193969727e-07\n","step = 4180: loss = 62.242671966552734\n","step = 4180: Average Return = -4.917383193969727e-07\n","step = 4190: loss = 162.8330535888672\n","step = 4190: Average Return = -4.917383193969727e-07\n","step = 4200: loss = 140.823486328125\n","step = 4200: Average Return = -4.917383193969727e-07\n","step = 4210: loss = 86.97502136230469\n","step = 4210: Average Return = -4.917383193969727e-07\n","step = 4220: loss = 150.44212341308594\n","step = 4220: Average Return = -4.917383193969727e-07\n","step = 4230: loss = 62.884002685546875\n","step = 4230: Average Return = -4.917383193969727e-07\n","step = 4240: loss = 122.53314971923828\n","step = 4240: Average Return = -4.917383193969727e-07\n","step = 4250: loss = 109.4266357421875\n","step = 4250: Average Return = -4.917383193969727e-07\n","step = 4260: loss = 72.70011901855469\n","step = 4260: Average Return = -4.917383193969727e-07\n","step = 4270: loss = 164.4734344482422\n","step = 4270: Average Return = -4.917383193969727e-07\n","step = 4280: loss = 174.55340576171875\n","step = 4280: Average Return = -4.917383193969727e-07\n","step = 4290: loss = 136.31777954101562\n","step = 4290: Average Return = -4.917383193969727e-07\n","step = 4300: loss = 65.46961975097656\n","step = 4300: Average Return = -4.917383193969727e-07\n","step = 4310: loss = 89.52367401123047\n","step = 4310: Average Return = -4.917383193969727e-07\n","step = 4320: loss = 208.7438201904297\n","step = 4320: Average Return = -4.917383193969727e-07\n","step = 4330: loss = 39.4869384765625\n","step = 4330: Average Return = -4.917383193969727e-07\n","step = 4340: loss = 105.07681274414062\n","step = 4340: Average Return = -4.917383193969727e-07\n","step = 4350: loss = 141.58969116210938\n","step = 4350: Average Return = -4.917383193969727e-07\n","step = 4360: loss = 118.44178771972656\n","step = 4360: Average Return = -4.917383193969727e-07\n","step = 4370: loss = 96.3783950805664\n","step = 4370: Average Return = -4.917383193969727e-07\n","step = 4380: loss = 87.96383666992188\n","step = 4380: Average Return = -4.917383193969727e-07\n","step = 4390: loss = 153.7777099609375\n","step = 4390: Average Return = -4.917383193969727e-07\n","step = 4400: loss = 167.3887176513672\n","step = 4400: Average Return = -4.917383193969727e-07\n","step = 4410: loss = 69.22245788574219\n","step = 4410: Average Return = -4.917383193969727e-07\n","step = 4420: loss = 108.77031707763672\n","step = 4420: Average Return = -4.917383193969727e-07\n","step = 4430: loss = 146.97796630859375\n","step = 4430: Average Return = -4.917383193969727e-07\n","step = 4440: loss = 61.541725158691406\n","step = 4440: Average Return = -4.917383193969727e-07\n","step = 4450: loss = 67.93270111083984\n","step = 4450: Average Return = -4.917383193969727e-07\n","step = 4460: loss = 122.76880645751953\n","step = 4460: Average Return = -4.917383193969727e-07\n","step = 4470: loss = 84.60697174072266\n","step = 4470: Average Return = -4.917383193969727e-07\n","step = 4480: loss = 66.91178131103516\n","step = 4480: Average Return = -4.917383193969727e-07\n","step = 4490: loss = 119.43182373046875\n","step = 4490: Average Return = -4.917383193969727e-07\n","step = 4500: loss = 140.990234375\n","step = 4500: Average Return = -4.917383193969727e-07\n","step = 4510: loss = 103.92539978027344\n","step = 4510: Average Return = -4.917383193969727e-07\n","step = 4520: loss = 121.72810363769531\n","step = 4520: Average Return = -4.917383193969727e-07\n","step = 4530: loss = 144.03395080566406\n","step = 4530: Average Return = -4.917383193969727e-07\n","step = 4540: loss = 89.73470306396484\n","step = 4540: Average Return = -4.917383193969727e-07\n","step = 4550: loss = 113.19651794433594\n","step = 4550: Average Return = -4.917383193969727e-07\n","step = 4560: loss = 142.54983520507812\n","step = 4560: Average Return = -4.917383193969727e-07\n","step = 4570: loss = 198.15533447265625\n","step = 4570: Average Return = -4.917383193969727e-07\n","step = 4580: loss = 95.57376098632812\n","step = 4580: Average Return = -3.2782554626464844e-07\n","step = 4590: loss = 124.70567321777344\n","step = 4590: Average Return = -3.2782554626464844e-07\n","step = 4600: loss = 112.20841217041016\n","step = 4600: Average Return = -3.2782554626464844e-07\n","step = 4610: loss = 65.20619201660156\n","step = 4610: Average Return = -4.917383193969727e-07\n","step = 4620: loss = 88.03219604492188\n","step = 4620: Average Return = -3.2782554626464844e-07\n","step = 4630: loss = 56.768009185791016\n","step = 4630: Average Return = -3.2782554626464844e-07\n","step = 4640: loss = 51.50072479248047\n","step = 4640: Average Return = -3.2782554626464844e-07\n","step = 4650: loss = 152.31439208984375\n","step = 4650: Average Return = -3.2782554626464844e-07\n","step = 4660: loss = 93.6615219116211\n","step = 4660: Average Return = -3.2782554626464844e-07\n","step = 4670: loss = 74.32376098632812\n","step = 4670: Average Return = -3.2782554626464844e-07\n","step = 4680: loss = 121.93943786621094\n","step = 4680: Average Return = -3.2782554626464844e-07\n","step = 4690: loss = 121.7177963256836\n","step = 4690: Average Return = -3.2782554626464844e-07\n","step = 4700: loss = 107.50131225585938\n","step = 4700: Average Return = -3.2782554626464844e-07\n","step = 4710: loss = 170.16845703125\n","step = 4710: Average Return = -3.2782554626464844e-07\n","step = 4720: loss = 134.22789001464844\n","step = 4720: Average Return = -3.2782554626464844e-07\n","step = 4730: loss = 206.7076873779297\n","step = 4730: Average Return = -3.2782554626464844e-07\n","step = 4740: loss = 193.47439575195312\n","step = 4740: Average Return = -3.2782554626464844e-07\n","step = 4750: loss = 147.34951782226562\n","step = 4750: Average Return = -3.2782554626464844e-07\n","step = 4760: loss = 288.4193115234375\n","step = 4760: Average Return = -3.2782554626464844e-07\n","step = 4770: loss = 196.2063446044922\n","step = 4770: Average Return = -3.2782554626464844e-07\n","step = 4780: loss = 67.04661560058594\n","step = 4780: Average Return = -3.2782554626464844e-07\n","step = 4790: loss = 108.03475189208984\n","step = 4790: Average Return = -3.2782554626464844e-07\n","step = 4800: loss = 150.43319702148438\n","step = 4800: Average Return = -3.2782554626464844e-07\n","step = 4810: loss = 84.7168960571289\n","step = 4810: Average Return = -3.2782554626464844e-07\n","step = 4820: loss = 102.99607849121094\n","step = 4820: Average Return = -3.2782554626464844e-07\n","step = 4830: loss = 130.35557556152344\n","step = 4830: Average Return = -3.2782554626464844e-07\n","step = 4840: loss = 63.764678955078125\n","step = 4840: Average Return = -3.2782554626464844e-07\n","step = 4850: loss = 98.44692993164062\n","step = 4850: Average Return = -3.2782554626464844e-07\n","step = 4860: loss = 165.1038055419922\n","step = 4860: Average Return = -3.2782554626464844e-07\n","step = 4870: loss = 77.71683502197266\n","step = 4870: Average Return = -3.2782554626464844e-07\n","step = 4880: loss = 141.25291442871094\n","step = 4880: Average Return = -3.2782554626464844e-07\n","step = 4890: loss = 92.53945922851562\n","step = 4890: Average Return = -3.2782554626464844e-07\n","step = 4900: loss = 111.20057678222656\n","step = 4900: Average Return = -3.2782554626464844e-07\n","step = 4910: loss = 181.88580322265625\n","step = 4910: Average Return = -3.2782554626464844e-07\n","step = 4920: loss = 55.0461540222168\n","step = 4920: Average Return = -3.2782554626464844e-07\n","step = 4930: loss = 92.71478271484375\n","step = 4930: Average Return = -3.2782554626464844e-07\n","step = 4940: loss = 147.52642822265625\n","step = 4940: Average Return = -3.2782554626464844e-07\n","step = 4950: loss = 154.624755859375\n","step = 4950: Average Return = -3.2782554626464844e-07\n","step = 4960: loss = 97.31819152832031\n","step = 4960: Average Return = -3.2782554626464844e-07\n","step = 4970: loss = 110.26103210449219\n","step = 4970: Average Return = -3.2782554626464844e-07\n","step = 4980: loss = 121.58051300048828\n","step = 4980: Average Return = -3.2782554626464844e-07\n","step = 4990: loss = 58.8336296081543\n","step = 4990: Average Return = -1.6391277313232422e-07\n","step = 5000: loss = 101.2461166381836\n","step = 5000: Average Return = -1.6391277313232422e-07\n","step = 5010: loss = 158.28709411621094\n","step = 5010: Average Return = -1.6391277313232422e-07\n","step = 5020: loss = 108.17350769042969\n","step = 5020: Average Return = -1.6391277313232422e-07\n","step = 5030: loss = 112.8142318725586\n","step = 5030: Average Return = -1.6391277313232422e-07\n","step = 5040: loss = 125.91625213623047\n","step = 5040: Average Return = -1.6391277313232422e-07\n","step = 5050: loss = 138.5109100341797\n","step = 5050: Average Return = -1.6391277313232422e-07\n","step = 5060: loss = 107.72843170166016\n","step = 5060: Average Return = -1.6391277313232422e-07\n","step = 5070: loss = 169.186767578125\n","step = 5070: Average Return = -1.6391277313232422e-07\n","step = 5080: loss = 233.6617431640625\n","step = 5080: Average Return = -1.6391277313232422e-07\n","step = 5090: loss = 99.2782974243164\n","step = 5090: Average Return = -1.6391277313232422e-07\n","step = 5100: loss = 57.124664306640625\n","step = 5100: Average Return = -1.6391277313232422e-07\n","step = 5110: loss = 91.31803131103516\n","step = 5110: Average Return = -1.6391277313232422e-07\n","step = 5120: loss = 130.87844848632812\n","step = 5120: Average Return = -1.6391277313232422e-07\n","step = 5130: loss = 119.56364440917969\n","step = 5130: Average Return = -1.6391277313232422e-07\n","step = 5140: loss = 124.1943359375\n","step = 5140: Average Return = -1.6391277313232422e-07\n","step = 5150: loss = 122.43004608154297\n","step = 5150: Average Return = -1.6391277313232422e-07\n","step = 5160: loss = 201.1104278564453\n","step = 5160: Average Return = -1.6391277313232422e-07\n","step = 5170: loss = 115.58320617675781\n","step = 5170: Average Return = -1.6391277313232422e-07\n","step = 5180: loss = 86.814453125\n","step = 5180: Average Return = -1.6391277313232422e-07\n","step = 5190: loss = 85.3814926147461\n","step = 5190: Average Return = -1.6391277313232422e-07\n","step = 5200: loss = 142.52540588378906\n","step = 5200: Average Return = -1.6391277313232422e-07\n","step = 5210: loss = 69.36507415771484\n","step = 5210: Average Return = -1.6391277313232422e-07\n","step = 5220: loss = 67.45537567138672\n","step = 5220: Average Return = -1.6391277313232422e-07\n","step = 5230: loss = 158.8201904296875\n","step = 5230: Average Return = -1.6391277313232422e-07\n","step = 5240: loss = 117.6211929321289\n","step = 5240: Average Return = -1.6391277313232422e-07\n","step = 5250: loss = 229.73538208007812\n","step = 5250: Average Return = -1.6391277313232422e-07\n","step = 5260: loss = 108.83183288574219\n","step = 5260: Average Return = -1.6391277313232422e-07\n","step = 5270: loss = 122.33238220214844\n","step = 5270: Average Return = -1.6391277313232422e-07\n","step = 5280: loss = 229.9321746826172\n","step = 5280: Average Return = -1.6391277313232422e-07\n","step = 5290: loss = 194.8065185546875\n","step = 5290: Average Return = -1.6391277313232422e-07\n","step = 5300: loss = 246.1175079345703\n","step = 5300: Average Return = -1.6391277313232422e-07\n","step = 5310: loss = 67.99205780029297\n","step = 5310: Average Return = -1.6391277313232422e-07\n","step = 5320: loss = 122.84886932373047\n","step = 5320: Average Return = -1.6391277313232422e-07\n","step = 5330: loss = 113.98021697998047\n","step = 5330: Average Return = -1.6391277313232422e-07\n","step = 5340: loss = 105.14179992675781\n","step = 5340: Average Return = -1.6391277313232422e-07\n","step = 5350: loss = 64.89424896240234\n","step = 5350: Average Return = -1.6391277313232422e-07\n","step = 5360: loss = 96.32617950439453\n","step = 5360: Average Return = -1.6391277313232422e-07\n","step = 5370: loss = 94.13101959228516\n","step = 5370: Average Return = -1.6391277313232422e-07\n","step = 5380: loss = 93.99893951416016\n","step = 5380: Average Return = -1.6391277313232422e-07\n","step = 5390: loss = 58.744384765625\n","step = 5390: Average Return = -1.6391277313232422e-07\n","step = 5400: loss = 122.69913482666016\n","step = 5400: Average Return = -1.6391277313232422e-07\n","step = 5410: loss = 58.49875259399414\n","step = 5410: Average Return = -1.6391277313232422e-07\n","step = 5420: loss = 111.4344711303711\n","step = 5420: Average Return = -1.6391277313232422e-07\n","step = 5430: loss = 100.38314819335938\n","step = 5430: Average Return = -1.6391277313232422e-07\n","step = 5440: loss = 146.89430236816406\n","step = 5440: Average Return = -1.6391277313232422e-07\n","step = 5450: loss = 88.59696197509766\n","step = 5450: Average Return = -1.6391277313232422e-07\n","step = 5460: loss = 112.15348052978516\n","step = 5460: Average Return = -1.6391277313232422e-07\n","step = 5470: loss = 93.39859771728516\n","step = 5470: Average Return = -1.6391277313232422e-07\n","step = 5480: loss = 82.21822357177734\n","step = 5480: Average Return = -1.6391277313232422e-07\n","step = 5490: loss = 165.7840576171875\n","step = 5490: Average Return = -1.6391277313232422e-07\n","step = 5500: loss = 106.17813873291016\n","step = 5500: Average Return = -1.6391277313232422e-07\n","step = 5510: loss = 238.02061462402344\n","step = 5510: Average Return = -1.6391277313232422e-07\n","step = 5520: loss = 101.07304382324219\n","step = 5520: Average Return = -1.6391277313232422e-07\n","step = 5530: loss = 156.90928649902344\n","step = 5530: Average Return = -1.6391277313232422e-07\n","step = 5540: loss = 215.14105224609375\n","step = 5540: Average Return = -1.6391277313232422e-07\n","step = 5550: loss = 76.43479919433594\n","step = 5550: Average Return = -1.6391277313232422e-07\n","step = 5560: loss = 119.51033020019531\n","step = 5560: Average Return = -1.6391277313232422e-07\n","step = 5570: loss = 207.065185546875\n","step = 5570: Average Return = -1.6391277313232422e-07\n","step = 5580: loss = 193.81729125976562\n","step = 5580: Average Return = -1.6391277313232422e-07\n","step = 5590: loss = 91.04058837890625\n","step = 5590: Average Return = -1.6391277313232422e-07\n","step = 5600: loss = 89.82711029052734\n","step = 5600: Average Return = -1.6391277313232422e-07\n","step = 5610: loss = 216.8139190673828\n","step = 5610: Average Return = -1.6391277313232422e-07\n","step = 5620: loss = 129.25096130371094\n","step = 5620: Average Return = -1.6391277313232422e-07\n","step = 5630: loss = 280.302001953125\n","step = 5630: Average Return = -1.6391277313232422e-07\n","step = 5640: loss = 153.67506408691406\n","step = 5640: Average Return = -1.6391277313232422e-07\n","step = 5650: loss = 144.47471618652344\n","step = 5650: Average Return = -1.6391277313232422e-07\n","step = 5660: loss = 165.79241943359375\n","step = 5660: Average Return = -1.6391277313232422e-07\n","step = 5670: loss = 129.51890563964844\n","step = 5670: Average Return = -1.6391277313232422e-07\n","step = 5680: loss = 73.16795349121094\n","step = 5680: Average Return = -1.6391277313232422e-07\n","step = 5690: loss = 120.21101379394531\n","step = 5690: Average Return = -1.6391277313232422e-07\n","step = 5700: loss = 189.7322998046875\n","step = 5700: Average Return = -1.6391277313232422e-07\n","step = 5710: loss = 99.60169219970703\n","step = 5710: Average Return = -1.6391277313232422e-07\n","step = 5720: loss = 104.38833618164062\n","step = 5720: Average Return = -1.6391277313232422e-07\n","step = 5730: loss = 131.10548400878906\n","step = 5730: Average Return = -1.6391277313232422e-07\n","step = 5740: loss = 89.6275634765625\n","step = 5740: Average Return = -1.6391277313232422e-07\n","step = 5750: loss = 99.01512145996094\n","step = 5750: Average Return = -1.6391277313232422e-07\n","step = 5760: loss = 97.61817932128906\n","step = 5760: Average Return = -1.6391277313232422e-07\n","step = 5770: loss = 146.1070556640625\n","step = 5770: Average Return = -1.6391277313232422e-07\n","step = 5780: loss = 86.23442840576172\n","step = 5780: Average Return = -1.6391277313232422e-07\n","step = 5790: loss = 176.32363891601562\n","step = 5790: Average Return = -1.6391277313232422e-07\n","step = 5800: loss = 74.87537384033203\n","step = 5800: Average Return = -1.6391277313232422e-07\n","step = 5810: loss = 186.95260620117188\n","step = 5810: Average Return = -1.6391277313232422e-07\n","step = 5820: loss = 165.6832275390625\n","step = 5820: Average Return = -1.6391277313232422e-07\n","step = 5830: loss = 164.49937438964844\n","step = 5830: Average Return = -1.6391277313232422e-07\n","step = 5840: loss = 113.67762756347656\n","step = 5840: Average Return = -1.6391277313232422e-07\n","step = 5850: loss = 82.73766326904297\n","step = 5850: Average Return = -1.6391277313232422e-07\n","step = 5860: loss = 103.46147918701172\n","step = 5860: Average Return = -1.6391277313232422e-07\n","step = 5870: loss = 70.7295913696289\n","step = 5870: Average Return = -1.6391277313232422e-07\n","step = 5880: loss = 82.67611694335938\n","step = 5880: Average Return = -1.6391277313232422e-07\n","step = 5890: loss = 92.04193115234375\n","step = 5890: Average Return = -1.6391277313232422e-07\n","step = 5900: loss = 66.72590637207031\n","step = 5900: Average Return = -1.6391277313232422e-07\n","step = 5910: loss = 160.1056671142578\n","step = 5910: Average Return = -1.6391277313232422e-07\n","step = 5920: loss = 110.4525146484375\n","step = 5920: Average Return = -1.6391277313232422e-07\n","step = 5930: loss = 88.8104476928711\n","step = 5930: Average Return = -1.6391277313232422e-07\n","step = 5940: loss = 128.58778381347656\n","step = 5940: Average Return = -1.6391277313232422e-07\n","step = 5950: loss = 86.98704528808594\n","step = 5950: Average Return = -1.6391277313232422e-07\n","step = 5960: loss = 112.08788299560547\n","step = 5960: Average Return = -1.6391277313232422e-07\n","step = 5970: loss = 68.7031478881836\n","step = 5970: Average Return = -1.6391277313232422e-07\n","step = 5980: loss = 81.3375244140625\n","step = 5980: Average Return = -1.6391277313232422e-07\n","step = 5990: loss = 119.2967758178711\n","step = 5990: Average Return = -1.6391277313232422e-07\n","step = 6000: loss = 222.6514434814453\n","step = 6000: Average Return = -1.6391277313232422e-07\n","step = 6010: loss = 64.72560119628906\n","step = 6010: Average Return = 0.0\n","step = 6020: loss = 116.55928039550781\n","step = 6020: Average Return = 0.0\n","step = 6030: loss = 61.71269226074219\n","step = 6030: Average Return = 0.0\n","step = 6040: loss = 113.58757781982422\n","step = 6040: Average Return = 0.0\n","step = 6050: loss = 118.53720092773438\n","step = 6050: Average Return = 0.0\n","step = 6060: loss = 248.2609405517578\n","step = 6060: Average Return = 0.0\n","step = 6070: loss = 117.69284057617188\n","step = 6070: Average Return = 0.0\n","step = 6080: loss = 269.0531311035156\n","step = 6080: Average Return = 0.0\n","step = 6090: loss = 163.5938262939453\n","step = 6090: Average Return = 0.0\n","step = 6100: loss = 68.07353210449219\n","step = 6100: Average Return = 0.0\n","step = 6110: loss = 240.60377502441406\n","step = 6110: Average Return = 0.0\n","step = 6120: loss = 147.5550537109375\n","step = 6120: Average Return = 0.0\n","step = 6130: loss = 141.81736755371094\n","step = 6130: Average Return = 0.0\n","step = 6140: loss = 140.60345458984375\n","step = 6140: Average Return = 0.0\n","step = 6150: loss = 150.2327117919922\n","step = 6150: Average Return = 0.0\n","step = 6160: loss = 127.10381317138672\n","step = 6160: Average Return = 0.0\n","step = 6170: loss = 152.56826782226562\n","step = 6170: Average Return = 0.0\n","step = 6180: loss = 80.55671691894531\n","step = 6180: Average Return = 0.0\n","step = 6190: loss = 131.5865478515625\n","step = 6190: Average Return = 0.0\n","step = 6200: loss = 285.5884704589844\n","step = 6200: Average Return = 0.0\n","step = 6210: loss = 68.2227783203125\n","step = 6210: Average Return = 0.0\n","step = 6220: loss = 102.01515197753906\n","step = 6220: Average Return = 0.0\n","step = 6230: loss = 318.0273742675781\n","step = 6230: Average Return = 0.0\n","step = 6240: loss = 85.63875579833984\n","step = 6240: Average Return = 0.0\n","step = 6250: loss = 99.28050231933594\n","step = 6250: Average Return = 0.0\n","step = 6260: loss = 150.10299682617188\n","step = 6260: Average Return = 0.0\n","step = 6270: loss = 88.41685485839844\n","step = 6270: Average Return = 0.0\n","step = 6280: loss = 128.37269592285156\n","step = 6280: Average Return = 0.0\n","step = 6290: loss = 228.6714630126953\n","step = 6290: Average Return = 0.0\n","step = 6300: loss = 128.48741149902344\n","step = 6300: Average Return = 0.0\n","step = 6310: loss = 147.54161071777344\n","step = 6310: Average Return = 0.0\n","step = 6320: loss = 122.94081115722656\n","step = 6320: Average Return = 0.0\n","step = 6330: loss = 139.6610870361328\n","step = 6330: Average Return = -1.6391277313232422e-07\n","step = 6340: loss = 149.50851440429688\n","step = 6340: Average Return = 0.0\n","step = 6350: loss = 98.45315551757812\n","step = 6350: Average Return = 0.0\n","step = 6360: loss = 78.93571472167969\n","step = 6360: Average Return = 0.0\n","step = 6370: loss = 138.35870361328125\n","step = 6370: Average Return = 0.0\n","step = 6380: loss = 228.88973999023438\n","step = 6380: Average Return = 0.0\n","step = 6390: loss = 92.46190643310547\n","step = 6390: Average Return = 0.0\n","step = 6400: loss = 146.44691467285156\n","step = 6400: Average Return = 0.0\n","step = 6410: loss = 118.25872039794922\n","step = 6410: Average Return = 0.0\n","step = 6420: loss = 109.44551086425781\n","step = 6420: Average Return = 0.0\n","step = 6430: loss = 84.91510772705078\n","step = 6430: Average Return = 0.0\n","step = 6440: loss = 237.26963806152344\n","step = 6440: Average Return = 0.0\n","step = 6450: loss = 103.21517181396484\n","step = 6450: Average Return = 0.0\n","step = 6460: loss = 136.62110900878906\n","step = 6460: Average Return = 0.0\n","step = 6470: loss = 65.81974792480469\n","step = 6470: Average Return = 0.0\n","step = 6480: loss = 165.69859313964844\n","step = 6480: Average Return = 0.0\n","step = 6490: loss = 194.10488891601562\n","step = 6490: Average Return = 0.0\n","step = 6500: loss = 72.77328491210938\n","step = 6500: Average Return = 0.0\n","step = 6510: loss = 86.02388763427734\n","step = 6510: Average Return = 0.0\n","step = 6520: loss = 85.3328628540039\n","step = 6520: Average Return = 0.0\n","step = 6530: loss = 346.4154052734375\n","step = 6530: Average Return = 0.0\n","step = 6540: loss = 74.47840881347656\n","step = 6540: Average Return = 0.0\n","step = 6550: loss = 85.98291015625\n","step = 6550: Average Return = 0.0\n","step = 6560: loss = 104.89276885986328\n","step = 6560: Average Return = 0.0\n","step = 6570: loss = 153.0214080810547\n","step = 6570: Average Return = 0.0\n","step = 6580: loss = 59.4968147277832\n","step = 6580: Average Return = 0.0\n","step = 6590: loss = 57.950523376464844\n","step = 6590: Average Return = 0.0\n","step = 6600: loss = 217.86123657226562\n","step = 6600: Average Return = 0.0\n","step = 6610: loss = 98.22003173828125\n","step = 6610: Average Return = 0.0\n","step = 6620: loss = 122.43779754638672\n","step = 6620: Average Return = 0.0\n","step = 6630: loss = 71.66665649414062\n","step = 6630: Average Return = 0.0\n","step = 6640: loss = 169.43482971191406\n","step = 6640: Average Return = 0.0\n","step = 6650: loss = 92.49217987060547\n","step = 6650: Average Return = 0.0\n","step = 6660: loss = 106.14898681640625\n","step = 6660: Average Return = 0.0\n","step = 6670: loss = 141.83331298828125\n","step = 6670: Average Return = 0.0\n","step = 6680: loss = 114.03848266601562\n","step = 6680: Average Return = 0.0\n","step = 6690: loss = 112.88890075683594\n","step = 6690: Average Return = 0.0\n","step = 6700: loss = 133.8433380126953\n","step = 6700: Average Return = 0.0\n","step = 6710: loss = 201.73878479003906\n","step = 6710: Average Return = 0.0\n","step = 6720: loss = 185.22279357910156\n","step = 6720: Average Return = 0.0\n","step = 6730: loss = 129.34835815429688\n","step = 6730: Average Return = 0.0\n","step = 6740: loss = 89.81693267822266\n","step = 6740: Average Return = 0.0\n","step = 6750: loss = 110.73031616210938\n","step = 6750: Average Return = 0.0\n","step = 6760: loss = 151.33721923828125\n","step = 6760: Average Return = 0.0\n","step = 6770: loss = 116.18171691894531\n","step = 6770: Average Return = 0.0\n","step = 6780: loss = 107.41082000732422\n","step = 6780: Average Return = 0.0\n","step = 6790: loss = 142.01516723632812\n","step = 6790: Average Return = 0.0\n","step = 6800: loss = 118.81260681152344\n","step = 6800: Average Return = 0.0\n","step = 6810: loss = 299.0210266113281\n","step = 6810: Average Return = 0.0\n","step = 6820: loss = 138.80908203125\n","step = 6820: Average Return = 0.0\n","step = 6830: loss = 223.09519958496094\n","step = 6830: Average Return = 0.0\n","step = 6840: loss = 66.39883422851562\n","step = 6840: Average Return = 0.0\n","step = 6850: loss = 82.52574157714844\n","step = 6850: Average Return = 0.0\n","step = 6860: loss = 83.55587005615234\n","step = 6860: Average Return = 0.0\n","step = 6870: loss = 78.08024597167969\n","step = 6870: Average Return = 0.0\n","step = 6880: loss = 233.79539489746094\n","step = 6880: Average Return = 0.0\n","step = 6890: loss = 93.50743103027344\n","step = 6890: Average Return = 0.0\n","step = 6900: loss = 76.23267364501953\n","step = 6900: Average Return = 0.0\n","step = 6910: loss = 103.90065002441406\n","step = 6910: Average Return = 0.0\n","step = 6920: loss = 166.58712768554688\n","step = 6920: Average Return = 0.0\n","step = 6930: loss = 84.60055541992188\n","step = 6930: Average Return = 0.0\n","step = 6940: loss = 50.801353454589844\n","step = 6940: Average Return = 0.0\n","step = 6950: loss = 85.34249114990234\n","step = 6950: Average Return = 0.0\n","step = 6960: loss = 149.56442260742188\n","step = 6960: Average Return = 0.0\n","step = 6970: loss = 138.82496643066406\n","step = 6970: Average Return = 0.0\n","step = 6980: loss = 70.1330337524414\n","step = 6980: Average Return = 0.0\n","step = 6990: loss = 121.96406555175781\n","step = 6990: Average Return = 0.0\n","step = 7000: loss = 92.1812973022461\n","step = 7000: Average Return = 0.0\n","step = 7010: loss = 190.64755249023438\n","step = 7010: Average Return = 0.0\n","step = 7020: loss = 117.13570404052734\n","step = 7020: Average Return = 0.0\n","step = 7030: loss = 99.93639373779297\n","step = 7030: Average Return = 0.0\n","step = 7040: loss = 122.82740020751953\n","step = 7040: Average Return = 0.0\n","step = 7050: loss = 129.22084045410156\n","step = 7050: Average Return = 0.0\n","step = 7060: loss = 160.5267333984375\n","step = 7060: Average Return = 0.0\n","step = 7070: loss = 128.76861572265625\n","step = 7070: Average Return = 0.0\n","step = 7080: loss = 112.74806213378906\n","step = 7080: Average Return = 0.0\n","step = 7090: loss = 69.7509994506836\n","step = 7090: Average Return = 0.0\n","step = 7100: loss = 82.68566131591797\n","step = 7100: Average Return = 0.0\n","step = 7110: loss = 187.68338012695312\n","step = 7110: Average Return = 0.0\n","step = 7120: loss = 82.38681030273438\n","step = 7120: Average Return = 0.0\n","step = 7130: loss = 207.20167541503906\n","step = 7130: Average Return = 0.0\n","step = 7140: loss = 119.1312255859375\n","step = 7140: Average Return = 0.0\n","step = 7150: loss = 216.17276000976562\n","step = 7150: Average Return = 0.0\n","step = 7160: loss = 259.38134765625\n","step = 7160: Average Return = 0.0\n","step = 7170: loss = 83.056640625\n","step = 7170: Average Return = 0.0\n","step = 7180: loss = 34.26617431640625\n","step = 7180: Average Return = 0.0\n","step = 7190: loss = 52.60923767089844\n","step = 7190: Average Return = 0.0\n","step = 7200: loss = 177.32901000976562\n","step = 7200: Average Return = 0.0\n","step = 7210: loss = 116.0039291381836\n","step = 7210: Average Return = 0.0\n","step = 7220: loss = 76.61323547363281\n","step = 7220: Average Return = 0.0\n","step = 7230: loss = 131.24032592773438\n","step = 7230: Average Return = 0.0\n","step = 7240: loss = 58.888572692871094\n","step = 7240: Average Return = 0.0\n","step = 7250: loss = 168.25404357910156\n","step = 7250: Average Return = 0.0\n","step = 7260: loss = 63.49590301513672\n","step = 7260: Average Return = 0.0\n","step = 7270: loss = 74.97174835205078\n","step = 7270: Average Return = 0.0\n","step = 7280: loss = 175.37191772460938\n","step = 7280: Average Return = 0.0\n","step = 7290: loss = 196.9817657470703\n","step = 7290: Average Return = 0.0\n","step = 7300: loss = 173.66323852539062\n","step = 7300: Average Return = 0.0\n","step = 7310: loss = 115.83135223388672\n","step = 7310: Average Return = 0.0\n","step = 7320: loss = 87.22405242919922\n","step = 7320: Average Return = 0.0\n","step = 7330: loss = 77.76117706298828\n","step = 7330: Average Return = 0.0\n","step = 7340: loss = 103.71133422851562\n","step = 7340: Average Return = 0.0\n","step = 7350: loss = 130.79559326171875\n","step = 7350: Average Return = 0.0\n","step = 7360: loss = 76.24561309814453\n","step = 7360: Average Return = 0.0\n","step = 7370: loss = 131.20639038085938\n","step = 7370: Average Return = 0.0\n","step = 7380: loss = 59.52363204956055\n","step = 7380: Average Return = 0.0\n","step = 7390: loss = 151.41029357910156\n","step = 7390: Average Return = 0.0\n","step = 7400: loss = 98.93504333496094\n","step = 7400: Average Return = 0.0\n","step = 7410: loss = 103.39598083496094\n","step = 7410: Average Return = 0.0\n","step = 7420: loss = 162.823486328125\n","step = 7420: Average Return = 0.0\n","step = 7430: loss = 113.26830291748047\n","step = 7430: Average Return = 0.0\n","step = 7440: loss = 167.58126831054688\n","step = 7440: Average Return = 0.0\n","step = 7450: loss = 178.0032958984375\n","step = 7450: Average Return = 0.0\n","step = 7460: loss = 54.31051254272461\n","step = 7460: Average Return = 0.0\n","step = 7470: loss = 85.73882293701172\n","step = 7470: Average Return = 0.0\n","step = 7480: loss = 131.9135284423828\n","step = 7480: Average Return = 0.0\n","step = 7490: loss = 137.69187927246094\n","step = 7490: Average Return = 0.0\n","step = 7500: loss = 63.51603698730469\n","step = 7500: Average Return = 0.0\n","step = 7510: loss = 135.1751708984375\n","step = 7510: Average Return = 0.0\n","step = 7520: loss = 133.5901336669922\n","step = 7520: Average Return = 0.0\n","step = 7530: loss = 126.44380187988281\n","step = 7530: Average Return = 0.0\n","step = 7540: loss = 52.50226974487305\n","step = 7540: Average Return = 0.0\n","step = 7550: loss = 136.5328369140625\n","step = 7550: Average Return = 0.0\n","step = 7560: loss = 130.4634552001953\n","step = 7560: Average Return = 0.0\n","step = 7570: loss = 80.2557373046875\n","step = 7570: Average Return = 0.0\n","step = 7580: loss = 112.87142944335938\n","step = 7580: Average Return = 0.0\n","step = 7590: loss = 71.50467681884766\n","step = 7590: Average Return = 0.0\n","step = 7600: loss = 118.37811279296875\n","step = 7600: Average Return = 0.0\n","step = 7610: loss = 193.063232421875\n","step = 7610: Average Return = 0.0\n","step = 7620: loss = 48.31424331665039\n","step = 7620: Average Return = 0.0\n","step = 7630: loss = 56.603309631347656\n","step = 7630: Average Return = 0.0\n","step = 7640: loss = 76.27210235595703\n","step = 7640: Average Return = 0.0\n","step = 7650: loss = 166.7686309814453\n","step = 7650: Average Return = 0.0\n","step = 7660: loss = 82.97493743896484\n","step = 7660: Average Return = 0.0\n","step = 7670: loss = 144.42466735839844\n","step = 7670: Average Return = 0.0\n","step = 7680: loss = 231.5928192138672\n","step = 7680: Average Return = 0.0\n","step = 7690: loss = 95.55449676513672\n","step = 7690: Average Return = 0.0\n","step = 7700: loss = 107.39018249511719\n","step = 7700: Average Return = 0.0\n","step = 7710: loss = 110.29519653320312\n","step = 7710: Average Return = 0.0\n","step = 7720: loss = 58.14759063720703\n","step = 7720: Average Return = 0.0\n","step = 7730: loss = 141.9244842529297\n","step = 7730: Average Return = 0.0\n","step = 7740: loss = 158.1438751220703\n","step = 7740: Average Return = 0.0\n","step = 7750: loss = 94.94632720947266\n","step = 7750: Average Return = 0.0\n","step = 7760: loss = 263.98712158203125\n","step = 7760: Average Return = 0.0\n","step = 7770: loss = 184.4114990234375\n","step = 7770: Average Return = 0.0\n","step = 7780: loss = 84.96717834472656\n","step = 7780: Average Return = 0.0\n","step = 7790: loss = 96.28292083740234\n","step = 7790: Average Return = 0.0\n","step = 7800: loss = 92.38140869140625\n","step = 7800: Average Return = 0.0\n","step = 7810: loss = 106.88804626464844\n","step = 7810: Average Return = 0.0\n","step = 7820: loss = 72.71636962890625\n","step = 7820: Average Return = 0.0\n","step = 7830: loss = 96.31311798095703\n","step = 7830: Average Return = 0.0\n","step = 7840: loss = 111.8504867553711\n","step = 7840: Average Return = 0.0\n","step = 7850: loss = 94.17638397216797\n","step = 7850: Average Return = 0.0\n","step = 7860: loss = 126.15065002441406\n","step = 7860: Average Return = 0.0\n","step = 7870: loss = 168.46124267578125\n","step = 7870: Average Return = 0.0\n","step = 7880: loss = 158.5228729248047\n","step = 7880: Average Return = 0.0\n","step = 7890: loss = 189.48394775390625\n","step = 7890: Average Return = 0.0\n","step = 7900: loss = 240.1764373779297\n","step = 7900: Average Return = 0.0\n","step = 7910: loss = 154.05935668945312\n","step = 7910: Average Return = 0.0\n","step = 7920: loss = 86.58448028564453\n","step = 7920: Average Return = 0.0\n","step = 7930: loss = 72.42310333251953\n","step = 7930: Average Return = 0.0\n","step = 7940: loss = 61.955265045166016\n","step = 7940: Average Return = 0.0\n","step = 7950: loss = 112.48168182373047\n","step = 7950: Average Return = 0.0\n","step = 7960: loss = 74.209716796875\n","step = 7960: Average Return = 0.0\n","step = 7970: loss = 73.22949981689453\n","step = 7970: Average Return = 0.0\n","step = 7980: loss = 186.3249053955078\n","step = 7980: Average Return = 0.0\n","step = 7990: loss = 157.49815368652344\n","step = 7990: Average Return = 0.0\n","step = 8000: loss = 97.21707916259766\n","step = 8000: Average Return = 0.0\n","step = 8010: loss = 130.3436279296875\n","step = 8010: Average Return = 0.0\n","step = 8020: loss = 106.56063842773438\n","step = 8020: Average Return = 0.0\n","step = 8030: loss = 73.67925262451172\n","step = 8030: Average Return = 0.0\n","step = 8040: loss = 78.44029235839844\n","step = 8040: Average Return = 0.0\n","step = 8050: loss = 112.49520111083984\n","step = 8050: Average Return = 0.0\n","step = 8060: loss = 161.8484649658203\n","step = 8060: Average Return = 0.0\n","step = 8070: loss = 148.05198669433594\n","step = 8070: Average Return = 0.0\n","step = 8080: loss = 135.55166625976562\n","step = 8080: Average Return = 0.0\n","step = 8090: loss = 59.39921188354492\n","step = 8090: Average Return = 0.0\n","step = 8100: loss = 104.21353149414062\n","step = 8100: Average Return = 0.0\n","step = 8110: loss = 63.970584869384766\n","step = 8110: Average Return = 0.0\n","step = 8120: loss = 37.751487731933594\n","step = 8120: Average Return = 0.0\n","step = 8130: loss = 69.29344940185547\n","step = 8130: Average Return = 0.0\n","step = 8140: loss = 162.69598388671875\n","step = 8140: Average Return = 0.0\n","step = 8150: loss = 110.53317260742188\n","step = 8150: Average Return = 0.0\n","step = 8160: loss = 167.10211181640625\n","step = 8160: Average Return = 0.0\n","step = 8170: loss = 106.4865951538086\n","step = 8170: Average Return = 0.0\n","step = 8180: loss = 86.43362426757812\n","step = 8180: Average Return = 0.0\n","step = 8190: loss = 44.833248138427734\n","step = 8190: Average Return = 0.0\n","step = 8200: loss = 92.39669799804688\n","step = 8200: Average Return = 0.0\n","step = 8210: loss = 70.17993927001953\n","step = 8210: Average Return = 0.0\n","step = 8220: loss = 93.982177734375\n","step = 8220: Average Return = 0.0\n","step = 8230: loss = 161.12155151367188\n","step = 8230: Average Return = 0.0\n","step = 8240: loss = 88.58688354492188\n","step = 8240: Average Return = 0.0\n","step = 8250: loss = 68.39981842041016\n","step = 8250: Average Return = 0.0\n","step = 8260: loss = 59.29722595214844\n","step = 8260: Average Return = 0.0\n","step = 8270: loss = 157.73504638671875\n","step = 8270: Average Return = 0.0\n","step = 8280: loss = 127.0706558227539\n","step = 8280: Average Return = 0.0\n","step = 8290: loss = 73.39900970458984\n","step = 8290: Average Return = 0.0\n","step = 8300: loss = 98.09849548339844\n","step = 8300: Average Return = 0.0\n","step = 8310: loss = 78.67327117919922\n","step = 8310: Average Return = 0.0\n","step = 8320: loss = 56.7431526184082\n","step = 8320: Average Return = 0.0\n","step = 8330: loss = 122.6925277709961\n","step = 8330: Average Return = 0.0\n","step = 8340: loss = 57.485084533691406\n","step = 8340: Average Return = 0.0\n","step = 8350: loss = 84.80453491210938\n","step = 8350: Average Return = 0.0\n","step = 8360: loss = 47.56596755981445\n","step = 8360: Average Return = 0.0\n","step = 8370: loss = 97.7333984375\n","step = 8370: Average Return = 0.0\n","step = 8380: loss = 133.0534210205078\n","step = 8380: Average Return = 0.0\n","step = 8390: loss = 62.52311325073242\n","step = 8390: Average Return = 0.0\n","step = 8400: loss = 85.05062103271484\n","step = 8400: Average Return = 0.0\n","step = 8410: loss = 53.43388748168945\n","step = 8410: Average Return = 0.0\n","step = 8420: loss = 117.0200424194336\n","step = 8420: Average Return = 0.0\n","step = 8430: loss = 50.865272521972656\n","step = 8430: Average Return = 0.0\n","step = 8440: loss = 118.63630676269531\n","step = 8440: Average Return = 0.0\n","step = 8450: loss = 85.6615219116211\n","step = 8450: Average Return = 0.0\n","step = 8460: loss = 186.4265594482422\n","step = 8460: Average Return = 0.0\n","step = 8470: loss = 107.65374755859375\n","step = 8470: Average Return = 0.0\n","step = 8480: loss = 61.17074966430664\n","step = 8480: Average Return = 0.0\n","step = 8490: loss = 152.48626708984375\n","step = 8490: Average Return = 0.0\n","step = 8500: loss = 59.395503997802734\n","step = 8500: Average Return = 0.0\n","step = 8510: loss = 75.6165771484375\n","step = 8510: Average Return = 0.0\n","step = 8520: loss = 133.99354553222656\n","step = 8520: Average Return = 0.0\n","step = 8530: loss = 175.44320678710938\n","step = 8530: Average Return = 0.0\n","step = 8540: loss = 50.857322692871094\n","step = 8540: Average Return = 0.0\n","step = 8550: loss = 65.7707748413086\n","step = 8550: Average Return = 0.0\n","step = 8560: loss = 164.8024139404297\n","step = 8560: Average Return = 0.0\n","step = 8570: loss = 156.26654052734375\n","step = 8570: Average Return = 0.0\n","step = 8580: loss = 179.52883911132812\n","step = 8580: Average Return = 0.0\n","step = 8590: loss = 103.4649658203125\n","step = 8590: Average Return = 0.0\n","step = 8600: loss = 86.25015258789062\n","step = 8600: Average Return = 0.0\n","step = 8610: loss = 88.01498413085938\n","step = 8610: Average Return = 0.0\n","step = 8620: loss = 176.5526885986328\n","step = 8620: Average Return = 0.0\n","step = 8630: loss = 89.21590423583984\n","step = 8630: Average Return = 0.0\n","step = 8640: loss = 132.95851135253906\n","step = 8640: Average Return = 0.0\n","step = 8650: loss = 78.55017852783203\n","step = 8650: Average Return = 0.0\n","step = 8660: loss = 89.8078842163086\n","step = 8660: Average Return = 0.0\n","step = 8670: loss = 101.21915435791016\n","step = 8670: Average Return = 0.0\n","step = 8680: loss = 77.96649932861328\n","step = 8680: Average Return = 0.0\n","step = 8690: loss = 127.50048065185547\n","step = 8690: Average Return = 0.0\n","step = 8700: loss = 114.9602279663086\n","step = 8700: Average Return = 0.0\n","step = 8710: loss = 207.6749725341797\n","step = 8710: Average Return = 0.0\n","step = 8720: loss = 183.3201904296875\n","step = 8720: Average Return = 0.0\n","step = 8730: loss = 164.1538848876953\n","step = 8730: Average Return = 0.0\n","step = 8740: loss = 191.64556884765625\n","step = 8740: Average Return = 0.0\n","step = 8750: loss = 60.99246597290039\n","step = 8750: Average Return = 0.0\n","step = 8760: loss = 80.98872375488281\n","step = 8760: Average Return = 0.0\n","step = 8770: loss = 106.12933349609375\n","step = 8770: Average Return = 0.0\n","step = 8780: loss = 92.87837982177734\n","step = 8780: Average Return = 0.0\n","step = 8790: loss = 163.0432586669922\n","step = 8790: Average Return = 0.0\n","step = 8800: loss = 88.24803161621094\n","step = 8800: Average Return = 0.0\n","step = 8810: loss = 112.94090270996094\n","step = 8810: Average Return = 0.0\n","step = 8820: loss = 76.49109649658203\n","step = 8820: Average Return = 0.0\n","step = 8830: loss = 169.22933959960938\n","step = 8830: Average Return = 0.0\n","step = 8840: loss = 70.96537017822266\n","step = 8840: Average Return = 0.0\n","step = 8850: loss = 301.7012939453125\n","step = 8850: Average Return = 0.0\n","step = 8860: loss = 101.6663589477539\n","step = 8860: Average Return = 0.0\n","step = 8870: loss = 204.4891815185547\n","step = 8870: Average Return = 0.0\n","step = 8880: loss = 137.45928955078125\n","step = 8880: Average Return = 0.0\n","step = 8890: loss = 163.00096130371094\n","step = 8890: Average Return = 0.0\n","step = 8900: loss = 62.79275894165039\n","step = 8900: Average Return = 0.0\n","step = 8910: loss = 77.20528411865234\n","step = 8910: Average Return = 0.0\n","step = 8920: loss = 102.42347717285156\n","step = 8920: Average Return = 0.0\n","step = 8930: loss = 160.42218017578125\n","step = 8930: Average Return = 0.0\n","step = 8940: loss = 68.97884368896484\n","step = 8940: Average Return = 0.0\n","step = 8950: loss = 85.67191314697266\n","step = 8950: Average Return = 0.0\n","step = 8960: loss = 58.07455825805664\n","step = 8960: Average Return = 0.0\n","step = 8970: loss = 263.9128112792969\n","step = 8970: Average Return = 0.0\n","step = 8980: loss = 96.26725769042969\n","step = 8980: Average Return = 0.0\n","step = 8990: loss = 178.03610229492188\n","step = 8990: Average Return = 0.0\n","step = 9000: loss = 53.04774475097656\n","step = 9000: Average Return = 0.0\n","step = 9010: loss = 87.81460571289062\n","step = 9010: Average Return = 0.0\n","step = 9020: loss = 89.54579162597656\n","step = 9020: Average Return = 0.0\n","step = 9030: loss = 159.40554809570312\n","step = 9030: Average Return = 0.0\n","step = 9040: loss = 88.80967712402344\n","step = 9040: Average Return = 0.0\n","step = 9050: loss = 149.2486114501953\n","step = 9050: Average Return = 0.0\n","step = 9060: loss = 104.96939849853516\n","step = 9060: Average Return = 0.0\n","step = 9070: loss = 85.14571380615234\n","step = 9070: Average Return = 0.0\n","step = 9080: loss = 71.39910125732422\n","step = 9080: Average Return = 0.0\n","step = 9090: loss = 293.3804931640625\n","step = 9090: Average Return = 0.0\n","step = 9100: loss = 176.02325439453125\n","step = 9100: Average Return = 0.0\n","step = 9110: loss = 197.0092315673828\n","step = 9110: Average Return = 0.0\n","step = 9120: loss = 84.31153106689453\n","step = 9120: Average Return = 0.0\n","step = 9130: loss = 72.4856948852539\n","step = 9130: Average Return = 0.0\n","step = 9140: loss = 75.32066345214844\n","step = 9140: Average Return = 0.0\n","step = 9150: loss = 123.1335220336914\n","step = 9150: Average Return = 0.0\n","step = 9160: loss = 108.61087036132812\n","step = 9160: Average Return = 0.0\n","step = 9170: loss = 97.48789978027344\n","step = 9170: Average Return = 0.0\n","step = 9180: loss = 160.95277404785156\n","step = 9180: Average Return = 0.0\n","step = 9190: loss = 101.60315704345703\n","step = 9190: Average Return = 0.0\n","step = 9200: loss = 122.3126449584961\n","step = 9200: Average Return = 0.0\n","step = 9210: loss = 81.80766296386719\n","step = 9210: Average Return = 0.0\n","step = 9220: loss = 202.3457794189453\n","step = 9220: Average Return = 0.0\n","step = 9230: loss = 76.04486083984375\n","step = 9230: Average Return = 0.0\n","step = 9240: loss = 227.6264190673828\n","step = 9240: Average Return = 0.0\n","step = 9250: loss = 88.9148178100586\n","step = 9250: Average Return = 0.0\n","step = 9260: loss = 69.00801849365234\n","step = 9260: Average Return = 0.0\n","step = 9270: loss = 67.37568664550781\n","step = 9270: Average Return = 0.0\n","step = 9280: loss = 155.26670837402344\n","step = 9280: Average Return = 0.0\n","step = 9290: loss = 88.27106475830078\n","step = 9290: Average Return = 0.0\n","step = 9300: loss = 122.0636978149414\n","step = 9300: Average Return = 0.0\n","step = 9310: loss = 221.1550750732422\n","step = 9310: Average Return = 0.0\n","step = 9320: loss = 204.42604064941406\n","step = 9320: Average Return = 0.0\n","step = 9330: loss = 92.52359008789062\n","step = 9330: Average Return = 0.0\n","step = 9340: loss = 122.79785919189453\n","step = 9340: Average Return = 0.0\n","step = 9350: loss = 90.54796600341797\n","step = 9350: Average Return = 0.0\n","step = 9360: loss = 93.1239013671875\n","step = 9360: Average Return = 0.0\n","step = 9370: loss = 88.02666473388672\n","step = 9370: Average Return = 0.0\n","step = 9380: loss = 176.5876007080078\n","step = 9380: Average Return = 0.0\n","step = 9390: loss = 108.25743865966797\n","step = 9390: Average Return = 0.0\n","step = 9400: loss = 61.66242599487305\n","step = 9400: Average Return = 0.0\n","step = 9410: loss = 216.9941864013672\n","step = 9410: Average Return = 0.0\n","step = 9420: loss = 165.5105743408203\n","step = 9420: Average Return = 0.0\n","step = 9430: loss = 144.19073486328125\n","step = 9430: Average Return = 0.0\n","step = 9440: loss = 95.74852752685547\n","step = 9440: Average Return = 0.0\n","step = 9450: loss = 100.3809814453125\n","step = 9450: Average Return = 0.0\n","step = 9460: loss = 217.4573974609375\n","step = 9460: Average Return = 0.0\n","step = 9470: loss = 48.24462890625\n","step = 9470: Average Return = 0.0\n","step = 9480: loss = 74.7189712524414\n","step = 9480: Average Return = 0.0\n","step = 9490: loss = 110.821044921875\n","step = 9490: Average Return = 0.0\n","step = 9500: loss = 84.99822998046875\n","step = 9500: Average Return = 0.0\n","step = 9510: loss = 83.93965148925781\n","step = 9510: Average Return = 0.0\n","step = 9520: loss = 141.8363494873047\n","step = 9520: Average Return = 0.0\n","step = 9530: loss = 51.02522277832031\n","step = 9530: Average Return = 0.0\n","step = 9540: loss = 65.25926971435547\n","step = 9540: Average Return = 0.0\n","step = 9550: loss = 47.88251876831055\n","step = 9550: Average Return = 0.0\n","step = 9560: loss = 134.30654907226562\n","step = 9560: Average Return = 0.0\n","step = 9570: loss = 93.13509368896484\n","step = 9570: Average Return = 0.0\n","step = 9580: loss = 82.35128021240234\n","step = 9580: Average Return = 0.0\n","step = 9590: loss = 98.97358703613281\n","step = 9590: Average Return = 0.0\n","step = 9600: loss = 205.9255828857422\n","step = 9600: Average Return = 0.0\n","step = 9610: loss = 123.1034927368164\n","step = 9610: Average Return = 0.0\n","step = 9620: loss = 61.27450180053711\n","step = 9620: Average Return = 0.0\n","step = 9630: loss = 192.4674835205078\n","step = 9630: Average Return = 0.0\n","step = 9640: loss = 126.7780532836914\n","step = 9640: Average Return = 0.0\n","step = 9650: loss = 59.48772430419922\n","step = 9650: Average Return = 0.0\n","step = 9660: loss = 207.6649627685547\n","step = 9660: Average Return = 0.0\n","step = 9670: loss = 33.76456832885742\n","step = 9670: Average Return = 0.0\n","step = 9680: loss = 56.44918441772461\n","step = 9680: Average Return = 0.0\n","step = 9690: loss = 77.37772369384766\n","step = 9690: Average Return = 0.0\n","step = 9700: loss = 138.75308227539062\n","step = 9700: Average Return = 0.0\n","step = 9710: loss = 116.1613998413086\n","step = 9710: Average Return = 0.0\n","step = 9720: loss = 159.57223510742188\n","step = 9720: Average Return = 0.0\n","step = 9730: loss = 82.67987823486328\n","step = 9730: Average Return = 0.0\n","step = 9740: loss = 197.18112182617188\n","step = 9740: Average Return = 0.0\n","step = 9750: loss = 85.3202133178711\n","step = 9750: Average Return = 0.0\n","step = 9760: loss = 64.63536071777344\n","step = 9760: Average Return = 0.0\n","step = 9770: loss = 112.162353515625\n","step = 9770: Average Return = 0.0\n","step = 9780: loss = 126.19007873535156\n","step = 9780: Average Return = 0.0\n","step = 9790: loss = 111.39189147949219\n","step = 9790: Average Return = 0.0\n","step = 9800: loss = 142.8943634033203\n","step = 9800: Average Return = 0.0\n","step = 9810: loss = 264.0893859863281\n","step = 9810: Average Return = 0.0\n","step = 9820: loss = 78.21344757080078\n","step = 9820: Average Return = 0.0\n","step = 9830: loss = 131.7645263671875\n","step = 9830: Average Return = 0.0\n","step = 9840: loss = 66.32562255859375\n","step = 9840: Average Return = 0.0\n","step = 9850: loss = 45.98802185058594\n","step = 9850: Average Return = 0.0\n","step = 9860: loss = 81.78050994873047\n","step = 9860: Average Return = 0.0\n","step = 9870: loss = 83.59593200683594\n","step = 9870: Average Return = 0.0\n","step = 9880: loss = 73.74195098876953\n","step = 9880: Average Return = 0.0\n","step = 9890: loss = 108.24911499023438\n","step = 9890: Average Return = 0.0\n","step = 9900: loss = 81.02237701416016\n","step = 9900: Average Return = 0.0\n","step = 9910: loss = 126.26802825927734\n","step = 9910: Average Return = 0.0\n","step = 9920: loss = 107.6365737915039\n","step = 9920: Average Return = 0.0\n","step = 9930: loss = 93.12028503417969\n","step = 9930: Average Return = 0.0\n","step = 9940: loss = 69.26651763916016\n","step = 9940: Average Return = 0.0\n","step = 9950: loss = 153.404541015625\n","step = 9950: Average Return = 0.0\n","step = 9960: loss = 223.7050018310547\n","step = 9960: Average Return = 0.0\n","step = 9970: loss = 113.925537109375\n","step = 9970: Average Return = 0.0\n","step = 9980: loss = 69.2512435913086\n","step = 9980: Average Return = 0.0\n","step = 9990: loss = 120.33795928955078\n","step = 9990: Average Return = 0.0\n","step = 10000: loss = 121.99256896972656\n","step = 10000: Average Return = 0.0\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-be730d6b58eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mself_play_train_ppo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mself_play_train_ppo\u001b[0m \u001b[0;34m= <function self_play_train_ppo at 0x7f599ba88840>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mtf_agent\u001b[0m \u001b[0;34m= <tf_agents.agents.ppo.ppo_clip_agent.PPOClipAgent object at 0x7f59989bec50>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36menv\u001b[0m \u001b[0;34m= <tf_agents.environments.tf_py_environment.TFPyEnvironment object at 0x7f599ba91f28>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mcreate_env\u001b[0m \u001b[0;34m= <function create_env at 0x7f599baaaf28>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mtc\u001b[0m \u001b[0;34m= <tf_agents.utils.common.Checkpointer object at 0x7f59989becc0>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mreplay_buffer\u001b[0m \u001b[0;34m= <tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object at 0x7f599ba98b70>\u001b[0m\n","\u001b[0;32m<ipython-input-9-35f21fc4f4fd>\u001b[0m in \u001b[0;36mself_play_train_ppo\u001b[0;34m(tf_agent=<tf_agents.agents.ppo.ppo_clip_agent.PPOClipAgent object>, train_env=<tf_agents.environments.tf_py_environment.TFPyEnvironment object>, eval_env=<tf_agents.environments.tf_py_environment.TFPyEnvironment object>, train_checkpointer=<tf_agents.utils.common.Checkpointer object>, replay_buffer=<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer object>)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mplt.plot\u001b[0m \u001b[0;34m= <function plot at 0x7f59f77e9730>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36msteps\u001b[0m \u001b[0;34m= range(0, 5005, 10)\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mreturns\u001b[0m \u001b[0;34m= [-2.614145, -2.6794894, -2.2188208, -0.93870723, -0.17054954, -0.01692304, -0.002696544, -0.0017413944, -0.000900954, -0.0008583814, -0.0007521063, -0.0007211417, -0.00041870773, -0.00022986531, -0.00014655292, -8.697808e-05, -0.0001013577, -0.00013831258, -0.00016650558, -0.00024211407, -0.0002949983, -0.00027742982, -0.00026585162, -0.0002014637, -0.00018656254, -0.00018763542, -0.00015494227, -0.00016497076, -0.00017999113, -0.00021973252, -0.00026489794, -0.00030598044, -0.00028553605, -0.00031016767, -0.00034107268, -0.00028003752, -0.00026756525, -0.00023812056, -0.0003129393, -0.00026911497, -0.000207901, -0.00015711784, -0.000118508935, -0.00010436773, -0.00010827184, -8.828938e-05, -7.3194504e-05, -7.107854e-05, -6.3449144e-05, -6.80238e-05, -7.215142e-05, -7.463992e-05, -6.4596534e-05, -6.6027045e-05, -6.318092e-05, -8.037686e-05, -7.806718e-05, -7.764995e-05, -7.4237585e-05, -6.876886e-05, -6.1929226e-05, -5.529821e-05, -4.775822e-05, -5.26309e-05, -5.2422285e-05, -5.3972006e-05, -5.2809715e-05, -5.763769e-05, -5.824864e-05, -5.64754e-05, -4.2304397e-05, -3.8787723e-05, -3.491342e-05, -3.2141805e-05, -3.4064054e-05, -2.9996037e-05, -2.8967857e-05, -2.6062131e-05, -2.540648e-05, -2.6062131e-05, -2.8327107e-05, -2.7865171e-05, -2.3037195e-05, -2.0980835e-05, -2.1636486e-05, -2.117455e-05, -2.2128224e-05, -2.1472573e-05, -2.2128224e-05, -2.361834e-05, -2.3111701e-05, -2.5570393e-05, -2.6881695e-05, -2.7373433e-05, -2.6881695e...\n\u001b[1;32m    105\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Return'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex=True, scaley=True, data=None, *args=(range(0, 5005, 10), [-2.614145, -2.6794894, -2.2188208, -0.93870723, -0.17054954, -0.01692304, -0.002696544, -0.0017413944, -0.000900954, -0.0008583814, -0.0007521063, -0.0007211417, -0.00041870773, -0.00022986531, -0.00014655292, -8.697808e-05, -0.0001013577, -0.00013831258, -0.00016650558, -0.00024211407, ...]), **kwargs={})\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m        \u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self=<matplotlib.axes._subplots.AxesSubplot object>, scalex=True, scaley=True, data=None, *args=(range(0, 5005, 10), [-2.614145, -2.6794894, -2.2188208, -0.93870723, -0.17054954, -0.01692304, -0.002696544, -0.0017413944, -0.000900954, -0.0008583814, -0.0007521063, -0.0007211417, -0.00041870773, -0.00022986531, -0.00014655292, -8.697808e-05, -0.0001013577, -0.00013831258, -0.00016650558, -0.00024211407, ...]), **kwargs={})\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mlines\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mself._get_lines\u001b[0m \u001b[0;34m= <matplotlib.axes._base._process_plot_var_args object at 0x7f59235c2eb8>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36margs\u001b[0m \u001b[0;34m= (range(0, 5005, 10), [-2.614145, -2.6794894, -2.2188208, -0.93870723, -0.17054954, -0.01692304, -0.002696544, -0.0017413944, -0.000900954, -0.0008583814, -0.0007521063, -0.0007211417, -0.00041870773, -0.00022986531, -0.00014655292, -8.697808e-05, -0.0001013577, -0.00013831258, -0.00016650558, -0.00024211407, -0.0002949983, -0.00027742982, -0.00026585162, -0.0002014637, -0.00018656254, -0.00018763542, -0.00015494227, -0.00016497076, -0.00017999113, -0.00021973252, -0.00026489794, -0.00030598044, -0.00028553605, -0.00031016767, -0.00034107268, -0.00028003752, -0.00026756525, -0.00023812056, -0.0003129393, -0.00026911497, -0.000207901, -0.00015711784, -0.000118508935, -0.00010436773, -0.00010827184, -8.828938e-05, -7.3194504e-05, -7.107854e-05, -6.3449144e-05, -6.80238e-05, -7.215142e-05, -7.463992e-05, -6.4596534e-05, -6.6027045e-05, -6.318092e-05, -8.037686e-05, -7.806718e-05, -7.764995e-05, -7.4237585e-05, -6.876886e-05, -6.1929226e-05, -5.529821e-05, -4.775822e-05, -5.26309e-05, -5.2422285e-05, -5.3972006e-05, -5.2809715e-05, -5.763769e-05, -5.824864e-05, -5.64754e-05, -4.2304397e-05, -3.8787723e-05, -3.491342e-05, -3.2141805e-05, -3.4064054e-05, -2.9996037e-05, -2.8967857e-05, -2.6062131e-05, -2.540648e-05, -2.6062131e-05, -2.8327107e-05, -2.7865171e-05, -2.3037195e-05, -2.0980835e-05, -2.1636486e-05, -2.117455e-05, -2.2128224e-05, -2.1472573e-05, -2.2128224e-05, -2.361834e-05, -2.3111701e-05, -2.5570393e-05, -2.6881695e-05, -2.737343...\n        \u001b[0m\u001b[0;36mdata\u001b[0m \u001b[0;34m= None\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=<matplotlib.axes._base._process_plot_var_args object>, *args=(), **kwargs={})\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mself._plot_args\u001b[0m \u001b[0;34m= <bound method _process_plot_var_args._plot_args of <matplotlib.axes._base._process_plot_var_args object at 0x7f59235c2eb8>>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mthis\u001b[0m \u001b[0;34m= (range(0, 5005, 10), [-2.614145, -2.6794894, -2.2188208, -0.93870723, -0.17054954, -0.01692304, -0.002696544, -0.0017413944, -0.000900954, -0.0008583814, -0.0007521063, -0.0007211417, -0.00041870773, -0.00022986531, -0.00014655292, -8.697808e-05, -0.0001013577, -0.00013831258, -0.00016650558, -0.00024211407, -0.0002949983, -0.00027742982, -0.00026585162, -0.0002014637, -0.00018656254, -0.00018763542, -0.00015494227, -0.00016497076, -0.00017999113, -0.00021973252, -0.00026489794, -0.00030598044, -0.00028553605, -0.00031016767, -0.00034107268, -0.00028003752, -0.00026756525, -0.00023812056, -0.0003129393, -0.00026911497, -0.000207901, -0.00015711784, -0.000118508935, -0.00010436773, -0.00010827184, -8.828938e-05, -7.3194504e-05, -7.107854e-05, -6.3449144e-05, -6.80238e-05, -7.215142e-05, -7.463992e-05, -6.4596534e-05, -6.6027045e-05, -6.318092e-05, -8.037686e-05, -7.806718e-05, -7.764995e-05, -7.4237585e-05, -6.876886e-05, -6.1929226e-05, -5.529821e-05, -4.775822e-05, -5.26309e-05, -5.2422285e-05, -5.3972006e-05, -5.2809715e-05, -5.763769e-05, -5.824864e-05, -5.64754e-05, -4.2304397e-05, -3.8787723e-05, -3.491342e-05, -3.2141805e-05, -3.4064054e-05, -2.9996037e-05, -2.8967857e-05, -2.6062131e-05, -2.540648e-05, -2.6062131e-05, -2.8327107e-05, -2.7865171e-05, -2.3037195e-05, -2.0980835e-05, -2.1636486e-05, -2.117455e-05, -2.2128224e-05, -2.1472573e-05, -2.2128224e-05, -2.361834e-05, -2.3111701e-05, -2.5570393e-05, -2.6881695e-05, -2.737343...\n        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self=<matplotlib.axes._base._process_plot_var_args object>, tup=(range(0, 5005, 10), [-2.614145, -2.6794894, -2.2188208, -0.93870723, -0.17054954, -0.01692304, -0.002696544, -0.0017413944, -0.000900954, -0.0008583814, -0.0007521063, -0.0007211417, -0.00041870773, -0.00022986531, -0.00014655292, -8.697808e-05, -0.0001013577, -0.00013831258, -0.00016650558, -0.00024211407, ...]), kwargs={})\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mValueError\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (501,) and (1001,)"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ZNHrPjROCn8Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":773},"executionInfo":{"status":"ok","timestamp":1596751993216,"user_tz":300,"elapsed":72356,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"a9f4baf4-0195-46d3-a453-fd6062a145b1"},"source":["save_checkpoint(fname, checkpoint_dir, tc, replay_buffer)\n","eval_returns(checkpoint_dir, fname, tc, create_env(), tf_agent.collect_policy)\n","save_policy(tf_agent, fname)\n","pol = extract_policy(get_policy_name(fname))\n","eval_returns_no_save(checkpoint_dir, fname, tc, create_env(), pol)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["self cooperate defect tit-for-tat [-0.9976613039523363 -0.02648646734654977 -0.9682146340608598\n"," -0.4236879617557862]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/policy/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/policy/assets\n"],"name":"stderr"},{"output_type":"stream","text":["self cooperate defect tit-for-tat [-1.0000000000000002 -0.04223513603210528 -1.0000000000000002\n"," -0.7500000000000001]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"EqIlvjfDLvY3","colab_type":"code","colab":{}},"source":["pol = extract_policy(get_policy_name(fname))\n","eval_returns_no_save(checkpoint_dir, fname, tc, create_env(), pol)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IfuNmQdyWlv","colab_type":"code","colab":{}},"source":["#unzip_cp(checkpoint_dir, fname, tc)\n","#nms = ['000', '045', '090', '135', '180', '225', '270', '315']\n","#def getnames(nms):\n","#  mynames = []\n","#  for i in range(len(nms)):\n","#    fn = \"svo-\" + nms[i] + \"-1-pgg1\"\n","#    mynames.append(\"gdrive/My Drive/colab+git/\"+fn+\"-cp/p/\"+fn+\"-p.zip\")\n","#  return mynames\n","#dirnames = getnames(nms)\n","#pol = extract_policy(dirnames[3])\n","\n","#eval_returns_no_save(checkpoint_dir, fname, tc, create_env(), pol)\n","#eval_returns_no_save(checkpoint_dir, fname, tc, create_env(), tf_agent.policy)\n","#make_graphs(\"svo-135-1-pgg1\")\n","#league(dirnames)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qtf25KX4sqvb","colab_type":"code","colab":{}},"source":["unzip_cp(checkpoint_dir, fname, tc)\n","checkpoint_dir = os.path.join(tempdir, fname)\n","env = create_env()\n","action_spec = array_spec.BoundedArraySpec(\n","    shape=(1,), dtype=np.float32, minimum=0, maximum=1, name='action')\n","tf_agent = construct_ppo_agent(env.observation_spec(), action_spec, env.time_step_spec())\n","replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","    data_spec=tf_agent.collect_data_spec,\n","    batch_size=env.batch_size,\n","    max_length=replay_buffer_capacity)\n","tc = make_checkpoint(tf_agent, env, checkpoint_dir, replay_buffer)\n","eval_returns_no_save(checkpoint_dir, fname, tc, create_env(), tf_agent.policy)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWEVL9dsnnEu","colab_type":"code","colab":{}},"source":["eval_returns_no_save(checkpoint_dir, fname, tc, create_env(), tf_agent.policy)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOalRIAm3wnV","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sRSoI9Cu7Jwi","colab_type":"code","colab":{}},"source":["replay_buffer.get_next()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ4FZQtkocqs","colab_type":"code","colab":{}},"source":["#self_play_train(tf_agent, env, create_env(), tc, replay_buffer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2YB1YGQRG4wR","colab_type":"code","colab":{}},"source":["#save_checkpoint(fname, checkpoint_dir, tc, replay_buffer)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXMlD0H89vU0","colab_type":"code","colab":{}},"source":["#unzip_cp(checkpoint_dir, fname, tc)\n","\n","#eval_returns(checkpoint_dir, fname, tc, create_env())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwtWqFvmVZig","colab_type":"code","colab":{}},"source":["#make_graphs(fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dmpjzrs4pSKW","colab_type":"code","colab":{}},"source":["\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAFSsQk8pW4l","colab_type":"code","colab":{}},"source":["%tensorboard --logdir logs"],"execution_count":null,"outputs":[]}]}