{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"master-training.ipynb","provenance":[],"authorship_tag":"ABX9TyO0cEwJdruzAfI9DIB2AFZb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"o-gfQLw1AcrE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1594004438881,"user_tz":300,"elapsed":2855,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"28937ee0-1da5-4cd2-818f-0065d908712e"},"source":["!pip install tf-agents\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf-agents in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.9.0)\n","Requirement already satisfied: gin-config==0.1.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.1.3)\n","Requirement already satisfied: tensorflow-probability>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.10.0)\n","Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (3.12.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.12.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.18.5)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf-agents) (0.3.3)\n","Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf-agents) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf-agents) (4.4.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.3->tf-agents) (47.3.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oCi38DvSIB7f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594004440431,"user_tz":300,"elapsed":4382,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"52ee7160-085b-4bd0-c068-54c656aff336"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import abc\n","import tensorflow as tf\n","import numpy as np\n","import random\n","\n","import base64\n","import IPython\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tempfile\n","import zipfile\n","import tensorflow_probability as tfp\n","\n","from tf_agents.environments import py_environment\n","from tf_agents.environments import tf_environment\n","from tf_agents.environments import tf_py_environment\n","from tf_agents.environments import utils\n","from tf_agents.specs import array_spec\n","from tf_agents.environments import wrappers\n","from tf_agents.trajectories import time_step as ts\n","from tf_agents.trajectories import policy_step as ps\n","from tf_agents.networks import actor_distribution_network\n","from tf_agents.networks import value_network\n","from tf_agents.networks import network\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\n","from tf_agents.trajectories import trajectory\n","from tf_agents.utils import common\n","from tf_agents.distributions.utils import SquashToSpecNormal\n","from tf_agents.networks import normal_projection_network\n","from tf_agents.policies import random_tf_policy\n","from tf_agents.policies import policy_saver\n","from tf_agents.specs import tensor_spec\n","from tf_agents.agents.sac import tanh_normal_projection_network\n","\n","from tf_agents.agents.ddpg import critic_network\n","from tf_agents.agents.sac import sac_agent\n","\n","\n","tf.compat.v1.enable_v2_behavior()\n","\n","import os\n","import shutil\n","\n","try:\n","  from google.colab import files\n","except ImportError:\n","  files = None\n","\n","\n","#from google.colab import drive \n","#drive.mount('/content/gdrive') \n","\n","tempdir = os.getenv(\"TEST_TMPDIR\", tempfile.gettempdir())\n","\n","\n","%xmode Verbose"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Exception reporting mode: Verbose\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LWrT_mfUZkm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594004440432,"user_tz":300,"elapsed":4363,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["# use \"num_iterations = 1e6\" for better results,\n","# 1e5 is just so this doesn't take too long. \n","num_iterations =  1000# @param {type:\"integer\"}\n","\n","initial_collect_steps = 10000 # @param {type:\"integer\"} \n","collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n","replay_buffer_capacity = 1000000 # @param {type:\"integer\"}\n","\n","batch_size = 256 # @param {type:\"integer\"}\n","\n","critic_learning_rate = 3e-4 # @param {type:\"number\"}\n","actor_learning_rate = 3e-4 # @param {type:\"number\"}\n","alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n","target_update_tau = 0.005 # @param {type:\"number\"}\n","target_update_period = 1 # @param {type:\"number\"}\n","gamma = 0.99 # @param {type:\"number\"}\n","reward_scale_factor = 1.0 # @param {type:\"number\"}\n","gradient_clipping = None # @param\n","\n","actor_fc_layer_params = (100, 100, 100)\n","critic_joint_fc_layer_params = (100, 100, 100)\n","\n","log_interval =  1000# @param {type:\"integer\"}\n","\n","num_eval_episodes =  10# @param {type:\"integer\"}\n","eval_interval = 1000 # @param {type:\"integer\"}\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qHOZ1AMSZ1y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594004440434,"user_tz":300,"elapsed":4354,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["_RHO = 0\n","def angular_reward(rho):\n","  return (lambda x, y: np.cos(rho) * x + np.sin(rho) * y)\n","def reward_fun(self, other):\n","  f = angular_reward(_RHO)\n","  return f(self, other)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRJDMuHeIIyf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594004440436,"user_tz":300,"elapsed":4345,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["\n","def construct_agent(observation_spec, action_spec, time_step_spec):\n","  agent_array_action_spec = action_spec\n","  agent_array_observation_spec = observation_spec\n","\n","  agent_action_spec = tensor_spec.from_spec(agent_array_action_spec)\n","  agent_observation_spec = tensor_spec.from_spec(agent_array_observation_spec)\n","\n","\n","  critic_net = critic_network.CriticNetwork(\n","    (agent_observation_spec, agent_action_spec),\n","    observation_fc_layer_params=None,\n","    action_fc_layer_params=None,\n","    joint_fc_layer_params=critic_joint_fc_layer_params)\n","\n","\n","  actor_net = actor_distribution_network.ActorDistributionNetwork(\n","    agent_observation_spec,\n","    agent_action_spec,\n","    fc_layer_params=actor_fc_layer_params,\n","    continuous_projection_net=tanh_normal_projection_network\n","        .TanhNormalProjectionNetwork\n","    )\n","\n","  value_net = value_network.ValueNetwork(observation_spec)\n","\n","  global_step = tf.compat.v1.train.get_or_create_global_step()\n","\n","  tf_agent = sac_agent.SacAgent(\n","      time_step_spec,\n","      agent_action_spec,\n","      actor_network=actor_net,\n","      critic_network=critic_net,\n","      actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n","          learning_rate=actor_learning_rate),\n","      critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n","          learning_rate=critic_learning_rate),\n","      alpha_optimizer=tf.compat.v1.train.AdamOptimizer(\n","          learning_rate=alpha_learning_rate),\n","      target_update_tau=target_update_tau,\n","      target_update_period=target_update_period,\n","      td_errors_loss_fn=tf.compat.v1.losses.mean_squared_error,\n","      gamma=gamma,\n","      reward_scale_factor=reward_scale_factor,\n","      gradient_clipping=gradient_clipping,\n","      train_step_counter=global_step)\n","  tf_agent.initialize()\n","  return tf_agent\n","\n","\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8pr8Qn7IOZt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594004440438,"user_tz":300,"elapsed":4336,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["class PublicGoodsEnv(py_environment.PyEnvironment):\n","  def __init__(self):\n","    self._action_spec = array_spec.BoundedArraySpec(\n","        shape=(2,), dtype=np.float32, minimum=0, maximum = 1, name='action')\n","    self._observation_spec = array_spec.BoundedArraySpec(\n","        shape=(11,2), dtype=np.float32, name='observation')\n","    s = np.full((11, 2), -1, dtype=np.float32)\n","    self._state = s\n","    self._episode_ended = False\n","    self._counter = 0\n","    self._END = 10\n","    self._MULT = 1.5\n","\n","\n","  def action_spec(self):\n","    return self._action_spec\n","\n","  def observation_spec(self):\n","    return self._observation_spec\n","\n","  def _reset(self):\n","    s = np.full((11, 2), -1, dtype=np.float32)\n","    self._state = s\n","    self._episode_ended = False\n","    self._counter = 0\n","    return ts.restart(np.array(self._state, dtype=np.float32))\n","\n","  def _step(self, action):\n","    self._counter += 1\n","\n","    if self._episode_ended:\n","      # The last action ended the episode. Ignore the current action and start\n","      # a new episode.\n","      return self.reset()\n","    \n","    self._state[self._counter - 1, 0] = action[0]\n","    self._state[self._counter - 1, 1] = action[1]\n","\n","    # Make sure episodes don't go on forever.\n","    if self._counter > self._END:\n","      self._episode_ended = True\n","\n","    s1 = 1\n","    a1 = self._state[self._counter - 1, 0] * s1\n","    s2 = 1\n","    a2 = self._state[self._counter - 1, 1] * s2\n","    s1_final = s1 - a1 + (a1 + a2)*self._MULT / 2\n","    s2_final = s2 - a2 + (a1 + a2)*self._MULT / 2\n","\n","    if self._episode_ended:\n","      reward_self = s1_final - s1\n","      reward_other = s2_final - s2\n","      my_reward = reward_fun(reward_self, reward_other)\n","\n","      ret = ts.termination(np.array(self._state, dtype=np.float32), my_reward)\n","      self._counter += 1\n","\n","      return ret\n","    else:\n","      reward_self = s1_final - s1\n","      reward_other = s2_final - s2\n","      my_reward = reward_fun(reward_self, reward_other)\n","      ret = ts.transition(\n","          np.array(self._state, dtype=np.float32), reward=my_reward, discount=1.0)\n","      #print(\"transition:\", ret)\n","      return ret\n","\n","def create_env():\n","  return tf_py_environment.TFPyEnvironment(PublicGoodsEnv())\n","\n","def validate_random(environment, episodes):\n","  time_step_spec = environment.time_step_spec()\n","  action_spec = environment.action_spec()\n","\n","  episode_count = 0\n","  time_step = environment.reset()\n","\n","  while episode_count < episodes:\n","    if not array_spec.check_arrays_nest(time_step, time_step_spec):\n","      raise ValueError(\n","          'Given `time_step`: %r does not match expected `time_step_spec`: %r' %\n","          (time_step, time_step_spec))\n","    obs = time_step.observation\n","    action0 = [random.uniform(0, 1)]\n","    action1 = [random.uniform(0, 1)]\n","\n","    new_action = [action0[0], action1[0]]\n","    time_step = environment.step(new_action)\n","    print(time_step)\n","\n","    if time_step.is_last():\n","        episode_count += 1\n","        time_step = environment.reset()\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOZwRy8MR6z6","colab_type":"code","colab":{}},"source":["def make_checkpoint(agent):\n","  train_checkpointer = common.Checkpointer(\n","      ckpt_dir=os.path.join(tempdir, 'checkpoint'),\n","      max_to_keep=1,\n","      agent=tf_agent,\n","      policy=tf_agent.policy,\n","      replay_buffer=replay_buffer,\n","      global_step=tf_agent.train_step_counter\n","  )\n","  rb_checkpointer = common.Checkpointer(\n","        ckpt_dir=os.path.join(tempdir, 'replay_buffer'),\n","        max_to_keep=1,\n","        replay_buffer=replay_buffer)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1uaZRfFYIVsx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594004440801,"user_tz":300,"elapsed":4685,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def self_play_train(rho, tf_agent, train_env, eval_env, train_checkpointer, rb_checkpointer):\n","  _RHO = rho\n","  def construct_intended_action(policy0, policy1, time_step, print_bool):\n","    action_step0 = policy0.action(time_step) \n","    if action_step0.action.numpy() < 0 or action_step0.action.numpy() > 1:\n","      print(\"WARNING OUT OF SPEC\")\n","\n","    obs = time_step.observation.numpy()[0]\n","    r, _ = np.shape(obs)\n","    for i in range(r):\n","      my_obs = obs[i]\n","      obs[i] = [my_obs[1], my_obs[0]]\n","    obs = tf.convert_to_tensor(np.array(obs, dtype=np.float32))\n","\n","    step_type = time_step.step_type.numpy()[0]\n","    step_type = tf.constant(step_type, dtype=tf.int32)      \n","\n","    reward = time_step.reward.numpy()[0]\n","    reward = tf.constant(reward, dtype=tf.float32)    \n","\n","    discount = time_step.discount.numpy()[0]\n","    discount = tf.constant(discount, dtype=tf.float32)\n","\n","    time_step = ts.TimeStep(step_type, reward, discount, obs)\n","    #print(\"time step edited\", time_step)\n","    action_step1 = policy1.action(time_step)\n","\n","    action0 = action_step0.action.numpy()[0]\n","    action1 = action_step1.action.numpy()\n","    if print_bool:\n","      print(action0)\n","      print(action1)\n","\n","    new_action = tf.convert_to_tensor(np.array([[action0[0], action1[0]]], dtype=np.float32))\n","    return new_action\n","  \n","  def compute_avg_return(environment, policy0, policy1, num_episodes=10):\n","\n","    total_return = 0.0\n","    for _ in range(num_episodes):\n","\n","      time_step = environment.reset()\n","      episode_return = 0.0\n","\n","      while not time_step.is_last():\n","        new_action = construct_intended_action(policy0, policy1, time_step, False)\n","        action_step = ps.PolicyStep(action=new_action)\n","\n","        time_step = environment.step(action_step.action)\n","        \n","        episode_return += time_step.reward\n","      total_return += episode_return\n","\n","    avg_return = total_return / num_episodes\n","    return avg_return.numpy()[0]\n","\n","\n","  replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","    data_spec=tf_agent.collect_data_spec,\n","    batch_size=train_env.batch_size,\n","    max_length=replay_buffer_capacity)\n","  \n","  def collect_step(environment, policy0, policy1):\n","\n","    time_step = environment.current_time_step()\n","\n","    new_action = construct_intended_action(policy0, policy1, time_step, False)\n","\n","    action_step = ps.PolicyStep(action=new_action)\n","\n","\n","    next_time_step = environment.step(action_step.action)\n","\n","    traj = trajectory.from_transition(time_step, action_step, next_time_step) #expand \n","\n","    # Add trajectory to the replay buffer\n","    replay_buffer.add_batch(traj)\n","\n","  def collect_data(env, policy0, policy1, steps):\n","    for _ in range(steps):\n","      collect_step(env, policy0, policy1)\n","\n","  collect_data(train_env, tf_agent.collect_policy, tf_agent.collect_policy, steps=100)\n","\n","  # Dataset generates trajectories with shape [Bx2x...]\n","  dataset = replay_buffer.as_dataset(\n","    num_parallel_calls=3, \n","    sample_batch_size=batch_size, \n","    num_steps=2).prefetch(3)\n","\n","  iterator = iter(dataset)\n","\n","  \n","  \n","  try:\n","    %%time\n","  except:\n","    pass\n","\n","  # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n","  tf_agent.train = common.function(tf_agent.train)\n","\n","  # Reset the train step\n","  tf_agent.train_step_counter.assign(0)\n","\n","  # Evaluate the agent's policy once before training.\n","  avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","  returns = [avg_return]\n","\n","  for _ in range(num_iterations):\n","    # Collect a few steps using collect_policy and save to the replay buffer.\n","    for _ in range(collect_steps_per_iteration):\n","      collect_step(train_env, tf_agent.collect_policy, tf_agent.collect_policy)\n","\n","    # Sample a batch of data from the buffer and update the agent's network.\n","\n","    experience, unused_info = next(iterator)\n","    train_loss = tf_agent.train(experience)\n","\n","    step = tf_agent.train_step_counter.numpy()\n","\n","    if step % log_interval == 0:\n","      print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n","\n","    if step % eval_interval == 0:\n","      avg_return = compute_avg_return(eval_env, tf_agent.policy, tf_agent.policy, num_eval_episodes)\n","      print('step = {0}: Average Return = {1}'.format(step, avg_return))\n","      returns.append(avg_return)\n","\n","\n","  steps = range(0, num_iterations + 1, eval_interval)\n","  plt.plot(steps, returns)\n","  plt.ylabel('Average Return')\n","  plt.xlabel('Step')\n","  plt.ylim(top=5.5)\n","\n","  train_checkpointer.save(tf_agent.train_step_counter.numpy())\n","  rb_checkpointer.save(global_step)\n","  def create_zip_file(dirname, base_filename):\n","    return shutil.make_archive(base_filename, 'zip', dirname)\n","\n","  def upload_and_unzip_file_to(dirname):\n","    if files is None:\n","      return\n","    uploaded = files.upload()\n","    for fn in uploaded.keys():\n","      print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","          name=fn, length=len(uploaded[fn])))\n","      shutil.rmtree(dirname)\n","      zip_files = zipfile.ZipFile(io.BytesIO(uploaded[fn]), 'r')\n","      zip_files.extractall(dirname)\n","      zip_files.close()\n","\n","  train_checkpointer.save(global_step)\n","  rb_checkpointer.save(global_step)\n","  return train_checkpointer, rb_checkpointer\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"-agaXo6mCpFQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594004440804,"user_tz":300,"elapsed":4684,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}}},"source":["def save_checkpoint(fname, train_checkpointer, rb_checkpointer):\n","  checkpoint_zip_filename = create_zip_file(os.path.join(tempdir, 'checkpoint'), os.path.join(tempdir, fname + '-cp'))\n","  rb_checkpoint_zip_filename = create_zip_file(os.path.join(tempdir, 'replay_buffer'), os.path.join(tempdir, fname + '-rb'))\n","  if files is not None:\n","    files.download(checkpoint_zip_filename) # try again if this fails: https://github.com/googlecolab/colabtools/issues/469\n","    files.download(rb_checkpoint_zip_filename)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wgKdwYGMLM0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1594004441881,"user_tz":300,"elapsed":5749,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"7c1847ed-026f-4ca6-e37d-37cb0e5dcc27"},"source":["env = create_env()\n","action_spec = array_spec.BoundedArraySpec(\n","    shape=(1,), dtype=np.float32, minimum=0, maximum=1, name='action')\n","tf_agent = construct_agent(env.observation_spec(), action_spec, env.time_step_spec())\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_agents/distributions/utils.py:92: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.\n","Instructions for updating:\n","`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nQ4FZQtkocqs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594005462915,"user_tz":300,"elapsed":1026767,"user":{"displayName":"Eugene Kim","photoUrl":"","userId":"12676049523427990866"}},"outputId":"a2b8228a-06b3-49b7-ce27-052815d40870"},"source":["self_play_train(\"svo-0-1\", 0, tf_agent, env, create_env())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n","Wall time: 6.91 µs\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not pass `graph_parents`.  They will  no longer be used.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not pass `graph_parents`.  They will  no longer be used.\n"],"name":"stderr"},{"output_type":"stream","text":["step = 1000: loss = -0.8703087568283081\n","step = 1000: Average Return = 3.135068893432617\n","step = 2000: loss = -1.3717602491378784\n","step = 2000: Average Return = 2.314446210861206\n","step = 3000: loss = -1.5030714273452759\n","step = 3000: Average Return = 2.3420557975769043\n","step = 4000: loss = -1.6679556369781494\n","step = 4000: Average Return = 2.1121127605438232\n","step = 5000: loss = -1.639918565750122\n","step = 5000: Average Return = 2.15676212310791\n","step = 6000: loss = -1.75389564037323\n","step = 6000: Average Return = 2.4310402870178223\n","step = 7000: loss = -1.685944676399231\n","step = 7000: Average Return = 2.220209836959839\n","step = 8000: loss = -1.9635357856750488\n","step = 8000: Average Return = 1.9318536520004272\n","step = 9000: loss = -1.7411715984344482\n","step = 9000: Average Return = 2.0196008682250977\n","step = 10000: loss = -1.2649762630462646\n","step = 10000: Average Return = 1.8101634979248047\n","step = 11000: loss = -1.234307050704956\n","step = 11000: Average Return = 2.005211591720581\n","step = 12000: loss = -0.6932279467582703\n","step = 12000: Average Return = 1.9554498195648193\n","step = 13000: loss = -1.186988353729248\n","step = 13000: Average Return = 2.1316540241241455\n","step = 14000: loss = -0.7022364139556885\n","step = 14000: Average Return = 1.7914674282073975\n","step = 15000: loss = -0.9006543755531311\n","step = 15000: Average Return = 2.271007776260376\n","step = 16000: loss = -1.0673902034759521\n","step = 16000: Average Return = 1.417472243309021\n","step = 17000: loss = -0.9446150660514832\n","step = 17000: Average Return = 1.9161174297332764\n","step = 18000: loss = -1.0447028875350952\n","step = 18000: Average Return = 1.7530088424682617\n","step = 19000: loss = -0.5014562606811523\n","step = 19000: Average Return = 1.8642358779907227\n","step = 20000: loss = -0.8273274898529053\n","step = 20000: Average Return = 1.9786230325698853\n","step = 21000: loss = -0.5044601559638977\n","step = 21000: Average Return = 1.605973482131958\n","step = 22000: loss = -0.7716723680496216\n","step = 22000: Average Return = 1.927865743637085\n","step = 23000: loss = -0.7624865174293518\n","step = 23000: Average Return = 2.2434048652648926\n","step = 24000: loss = -1.318230390548706\n","step = 24000: Average Return = 2.3155148029327393\n","step = 25000: loss = -0.7849515080451965\n","step = 25000: Average Return = 1.9201027154922485\n","step = 26000: loss = -1.0073468685150146\n","step = 26000: Average Return = 1.9336261749267578\n","step = 27000: loss = -0.6077343225479126\n","step = 27000: Average Return = 1.917228102684021\n","step = 28000: loss = -0.8446311354637146\n","step = 28000: Average Return = 1.741304636001587\n","step = 29000: loss = -0.6858731508255005\n","step = 29000: Average Return = 1.92812180519104\n","step = 30000: loss = -1.0385637283325195\n","step = 30000: Average Return = 1.9113651514053345\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-71133e9ce436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mself_play_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"svo-0-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mself_play_train\u001b[0m \u001b[0;34m= <function self_play_train at 0x7f8911ce4f28>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mtf_agent\u001b[0m \u001b[0;34m= <tf_agents.agents.sac.sac_agent.SacAgent object at 0x7f890f430da0>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36menv\u001b[0m \u001b[0;34m= <tf_agents.environments.tf_py_environment.TFPyEnvironment object at 0x7f8911cc4f98>\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mcreate_env\u001b[0m \u001b[0;34m= <function create_env at 0x7f8911cfe840>\u001b[0m\n","\u001b[0;32m<ipython-input-7-9946bcf51862>\u001b[0m in \u001b[0;36mself_play_train\u001b[0;34m(fname='svo-0-1', rho=0, tf_agent=<tf_agents.agents.sac.sac_agent.SacAgent object>, train_env=<tf_agents.environments.tf_py_environment.TFPyEnvironment object>, eval_env=<tf_agents.environments.tf_py_environment.TFPyEnvironment object>)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0mtrain_checkpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m   \u001b[0mtf_policy_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mtf_policy_saver.save\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mpolicy_dir\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcreate_zip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf_policy_saver' is not defined"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}